{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "bert.to(device)\n",
    "bert.cuda()\n",
    "\n",
    "encoded_input = tokenizer([\"test 1\",\"test 2\"], return_tensors='pt')\n",
    "encoded_input.to(device)\n",
    "output = bert(**encoded_input)\n",
    "print(output[\"pooler_output\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataFrame = pd.read_pickle(r'../data/7587_corrige.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stagiaire ingénieur en intelligence artificiel...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stagiaire en développement logiciel Développem...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stagiaire en développement Web Création et évo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stagiaire en développement Web Portage d’une a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Développeur Data / IA Développement d'applicat...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11281</th>\n",
       "      <td>Opérateur production Montage de transmission a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11282</th>\n",
       "      <td>Opérateur production Montage de transmission a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11283</th>\n",
       "      <td>Technicien réparation informatique Reparation ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>Technicien réparation Reparation &amp; maintenance...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11286</th>\n",
       "      <td>Développeur web freelance Webdesign &amp; Infographie</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "2      Stagiaire ingénieur en intelligence artificiel...    4.0\n",
       "3      Stagiaire en développement logiciel Développem...    2.0\n",
       "4      Stagiaire en développement Web Création et évo...    1.0\n",
       "5      Stagiaire en développement Web Portage d’une a...    0.0\n",
       "6      Développeur Data / IA Développement d'applicat...    4.0\n",
       "...                                                  ...    ...\n",
       "11281  Opérateur production Montage de transmission a...    1.0\n",
       "11282  Opérateur production Montage de transmission a...    1.0\n",
       "11283  Technicien réparation informatique Reparation ...    0.0\n",
       "11284  Technicien réparation Reparation & maintenance...    0.0\n",
       "11286  Développeur web freelance Webdesign & Infographie    0.0\n",
       "\n",
       "[5167 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = dataFrame[['jobTitle', 'description', 'label']].copy()\n",
    "\n",
    "subset.reset_index(drop=True, inplace=True)\n",
    "subset.replace('', np.nan, inplace=True)\n",
    "subset.dropna(inplace=True)\n",
    "\n",
    "subset['text'] = subset['jobTitle'] + ' ' + subset['description']\n",
    "subset = subset[['text','label']]\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 10 # Number of samples per class in the support set\n",
    "\n",
    "def gen_support_set(n_shots, tokenizer, dataset):\n",
    "    target_values = dataset[\"label\"].unique()\n",
    "    \n",
    "    shuffled_dataset = dataset.sample(frac = 1)\n",
    "    support_set = {}\n",
    "    for t in target_values:\n",
    "        current_target_dataset = shuffled_dataset[shuffled_dataset[\"label\"] == t]\n",
    "        support_set[t] = []\n",
    "        for i in range(n_shots):\n",
    "            encoded_input = tokenizer(current_target_dataset.iloc[i][\"text\"], return_tensors='pt', truncation=True)\n",
    "            encoded_input.to(device)\n",
    "            support_set[t].append(encoded_input)\n",
    "    return support_set\n",
    "    \n",
    "support_set = gen_support_set(n_shots, tokenizer, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_support_set(support_set, bert):\n",
    "    embeddings_support_set = {}\n",
    "    for t in support_set.keys():\n",
    "        embeddings_support_set[t] = []\n",
    "        for i in range(len(support_set[t])):\n",
    "            output = bert(**(support_set[t][i]))[\"pooler_output\"]\n",
    "            embeddings_support_set[t].append(output)\n",
    "    return embeddings_support_set\n",
    "\n",
    "embeddings_support_set = get_embeddings_support_set(support_set, bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "def predict(tokenizer, bert, instance, support_set):\n",
    "    encoded_input = tokenizer(instance, return_tensors='pt', truncation=True)\n",
    "    encoded_input.to(device)\n",
    "    embedding = bert(**encoded_input)[\"pooler_output\"]\n",
    "    similarities = []\n",
    "    \n",
    "    embeddings_support_set = get_embeddings_support_set(support_set, bert)\n",
    "    \n",
    "    for key in embeddings_support_set.keys():\n",
    "        similarities_current_key = []\n",
    "        for item in embeddings_support_set[key]:\n",
    "            similarity = torch.nn.functional.cosine_similarity(embedding, item)\n",
    "            similarities_current_key.append(torch.mean(similarity))\n",
    "        similarities.append(torch.max(torch.stack(similarities_current_key))) # Take the closest element of the support set for the class key to the input\n",
    "    return list(embeddings_support_set.keys())[torch.argmax(torch.stack(similarities))] # Take the closest element of all classes and return its class label\n",
    "\n",
    "print(predict(tokenizer, bert, subset.iloc[0][\"text\"], support_set))\n",
    "print(subset.iloc[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batches(training_set, tokenizer, batch_size):\n",
    "    batches = []\n",
    "    shuffled_set = training_set.sample(frac=1)\n",
    "\n",
    "    nb_batches = len(shuffled_set) // batch_size\n",
    "    \n",
    "    k = 0\n",
    "    len_shuffled_set = len(shuffled_set)\n",
    "    unprocessed_data = shuffled_set[\"text\"].tolist()\n",
    "    \n",
    "    for i in range(nb_batches):\n",
    "        j = 0\n",
    "        labels = []\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        unprocessed_batch = unprocessed_data[start:end]\n",
    "        inputs = tokenizer(unprocessed_batch, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        while(j<batch_size and k<len_shuffled_set):\n",
    "            labels.append(shuffled_set.iloc[k][\"label\"])\n",
    "            k += 1\n",
    "            j += 1\n",
    "        batches.append((inputs, labels))\n",
    "            \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(dataset, ratio):\n",
    "    test_set = dataset.sample(frac = ratio)\n",
    "    train_set = dataset.drop(test_set.index)\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / 10\n",
      "Batch:  0 / 5\n",
      "Batch:  1 / 5\n",
      "Batch:  2 / 5\n",
      "Batch:  3 / 5\n",
      "Batch:  4 / 5\n",
      "loss: 0.75\n",
      "Epoch:  1 / 10\n",
      "Batch:  0 / 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\Ingé\\4e année\\ProjetLinkedin\\2024_01_17 ING2 Projet\\notebooks\\bertTest.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Ing%C3%A9/4e%20ann%C3%A9e/ProjetLinkedin/2024_01_17%20ING2%20Projet/notebooks/bertTest.ipynb#X22sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     epoch_mean_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Ing%C3%A9/4e%20ann%C3%A9e/ProjetLinkedin/2024_01_17%20ING2%20Projet/notebooks/bertTest.ipynb#X22sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(bert\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Ing%C3%A9/4e%20ann%C3%A9e/ProjetLinkedin/2024_01_17%20ING2%20Projet/notebooks/bertTest.ipynb#X22sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Ing%C3%A9/4e%20ann%C3%A9e/ProjetLinkedin/2024_01_17%20ING2%20Projet/notebooks/bertTest.ipynb#X22sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Ing%C3%A9/4e%20ann%C3%A9e/ProjetLinkedin/2024_01_17%20ING2%20Projet/notebooks/bertTest.ipynb#X22sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m epoch_mean_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batches)\n",
      "File \u001b[1;32mg:\\Ingé\\4e année\\ProjetLinkedin\\2024_01_17 ING2 Projet\\.venv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mg:\\Ingé\\4e année\\ProjetLinkedin\\2024_01_17 ING2 Projet\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subset_trunc = subset.head(100)\n",
    "train_set, test_set = split_train_test(subset_trunc, 0.2)\n",
    "n_epochs = 10\n",
    "optimizer = torch.optim.AdamW(bert.parameters())\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "bert.zero_grad()\n",
    "\n",
    "try:\n",
    "    for epoch in range(n_epochs):\n",
    "        batches = gen_batches(train_set, tokenizer, 16)\n",
    "        print(\"Epoch: \", epoch, \"/\",n_epochs)\n",
    "        b = 0\n",
    "        epoch_mean_loss = 0\n",
    "        for batch in batches:\n",
    "            optimizer.zero_grad()\n",
    "            bert.train()\n",
    "            inputs, labels = batch\n",
    "            print(\"Batch: \", b, \"/\",len(batches))\n",
    "            b += 1\n",
    "            predictions = []\n",
    "            inputs.to(device)\n",
    "            bert_output = bert(**inputs)[\"pooler_output\"]\n",
    "            losses = []\n",
    "            \n",
    "            \n",
    "            embeddings_support_set = get_embeddings_support_set(support_set, bert)\n",
    "\t\t\n",
    "            for i in range(len(bert_output)):\n",
    "                input2 = torch.unsqueeze(bert_output[i],0)\n",
    "                input2.to(device)\n",
    "                for j in embeddings_support_set.keys():\n",
    "                    current_class_support_data = embeddings_support_set[j]\n",
    "                    target = torch.tensor([1.0]) if j == labels[i] else torch.tensor([-1.0])\n",
    "                    target = target.to(device)\n",
    "                    for n in range(n_shots):\n",
    "                        losses.append(torch.nn.functional.cosine_embedding_loss(current_class_support_data[n], input2, target))\n",
    "                    \n",
    "            loss = torch.mean(torch.stack(losses))\n",
    "            epoch_mean_loss += loss.item()\n",
    "                        \n",
    "            torch.nn.utils.clip_grad_norm_(bert.parameters(), 1.0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_mean_loss /= len(batches)\n",
    "        print(f\"loss: {epoch_mean_loss:.2f}\")\n",
    "finally:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(predict(tokenizer, bert, subset.iloc[0][\"text\"], support_set))\n",
    "print(subset.iloc[0][\"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
