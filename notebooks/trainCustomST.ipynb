{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is from https://github.com/UKPLab/sentence-transformers/tree/master/\n",
    "Paper authors: Reimers, Nils and Gurevych, Iryna\n",
    "\"\"\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, models, evaluation, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.datasets import ParallelSentencesDataset\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import sentence_transformers.util\n",
    "import csv\n",
    "import gzip\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", level=logging.INFO, handlers=[LoggingHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "teacher_model_name = (\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\"  # Our monolingual teacher model, we want to convert to multiple languages\n",
    ")\n",
    "student_model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"  # Model we use to imitate the teacher model\n",
    "\n",
    "max_seq_length = 128  # Student model max. lengths for inputs (number of word pieces)\n",
    "train_batch_size = 64  # Batch size for training\n",
    "inference_batch_size = 64  # Batch size at inference\n",
    "max_sentences_per_language = 500000  # Maximum number of  parallel sentences for training\n",
    "train_max_sentence_length = 250  # Maximum length (characters) for parallel training sentences\n",
    "\n",
    "num_epochs = 5  # Train for x epochs\n",
    "num_warmup_steps = 10000  # Warumup steps\n",
    "\n",
    "num_evaluation_steps = 1000  # Evaluate performance after every xxxx steps\n",
    "dev_sentences = 1000  # Number of parallel sentences to be used for development\n",
    "\n",
    "\n",
    "# Define the language codes you would like to extend the model to\n",
    "source_languages = set([\"en\"])  # Our teacher model accepts English (en) sentences\n",
    "target_languages = set([\"fr\"])  # We want to extend the model to these new languages. For language codes, see the header of the train file\n",
    "\n",
    "\n",
    "output_path = (\n",
    "    \"output/make-multilingual-\"\n",
    "    + \"-\".join(sorted(list(source_languages)) + sorted(list(target_languages)))\n",
    "    + \"-\"\n",
    "    + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    ")\n",
    "\n",
    "\n",
    "# This function downloads a corpus if it does not exist\n",
    "def download_corpora(filepaths):\n",
    "    if not isinstance(filepaths, list):\n",
    "        filepaths = [filepaths]\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        if not os.path.exists(filepath):\n",
    "            print(filepath, \"does not exists. Try to download from server\")\n",
    "            filename = os.path.basename(filepath)\n",
    "            url = \"https://sbert.net/datasets/\" + filename\n",
    "            sentence_transformers.util.http_get(url, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if the file exists. If not, they are downloaded...\n",
      "Create parallel files for the selected language combinations...\n",
      "2024-03-16 20:17:11 - Load teacher model\n",
      "2024-03-16 20:17:11 - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-mpnet-base-v2\n",
      "2024-03-16 20:17:12 - Use pytorch device_name: cuda\n",
      "2024-03-16 20:17:12 - Create student model from scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a2966d546e400cab2426afe270ca6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\HuggingFaceTokens\\hub\\models--Muennighoff--SGPT-125M-weightedmean-nli-bitfit. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623563c928d847cc9354155fa617ea74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39714e4fb6249a088a179c62f0d7602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc52e2f3e7c7416287e6d9b93a9b8696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0eadcbc8ad4b6296603e82781fbd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2450ab94d2184fc0a8637d2b1ddbe4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190d2795ec674283954526cca7c96dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:17:35 - Use pytorch device_name: cuda\n",
      "Read Parallel Sentences Dataset...\n",
      "2024-03-16 20:17:35 - Load parallel-sentences/talks-en-fr-train.tsv.gz\n",
      "Evaluate cross-lingual performance on different tasks...\n",
      "2024-03-16 20:17:37 - Create evaluator for parallel-sentences/talks-en-fr-dev.tsv.gz\n",
      "Read cross-lingual Semantic Textual Similarity (STS) data...\n"
     ]
    }
   ],
   "source": [
    "# Here we define train train and dev corpora\n",
    "train_corpus = \"datasets/parallel-sentences.tsv.gz\"\n",
    "sts_corpus = \"datasets/stsbenchmark.zip\"\n",
    "parallel_sentences_folder = \"parallel-sentences/\"\n",
    "\n",
    "print(\"Check if the file exists. If not, they are downloaded...\")\n",
    "# Check if the file exists. If not, they are downloaded\n",
    "download_corpora([train_corpus, sts_corpus])\n",
    "\n",
    "print(\"Create parallel files for the selected language combinations...\")\n",
    "# Create parallel files for the selected language combinations\n",
    "os.makedirs(parallel_sentences_folder, exist_ok=True)\n",
    "train_files = []\n",
    "dev_files = []\n",
    "files_to_create = []\n",
    "for source_lang in source_languages:\n",
    "    for target_lang in target_languages:\n",
    "        output_filename_train = os.path.join(\n",
    "            parallel_sentences_folder, \"talks-{}-{}-train.tsv.gz\".format(source_lang, target_lang)\n",
    "        )\n",
    "        output_filename_dev = os.path.join(\n",
    "            parallel_sentences_folder, \"talks-{}-{}-dev.tsv.gz\".format(source_lang, target_lang)\n",
    "        )\n",
    "        train_files.append(output_filename_train)\n",
    "        dev_files.append(output_filename_dev)\n",
    "        if not os.path.exists(output_filename_train) or not os.path.exists(output_filename_dev):\n",
    "            files_to_create.append(\n",
    "                {\n",
    "                    \"src_lang\": source_lang,\n",
    "                    \"trg_lang\": target_lang,\n",
    "                    \"fTrain\": gzip.open(output_filename_train, \"wt\", encoding=\"utf8\"),\n",
    "                    \"fDev\": gzip.open(output_filename_dev, \"wt\", encoding=\"utf8\"),\n",
    "                    \"devCount\": 0,\n",
    "                }\n",
    "            )\n",
    "\n",
    "if len(files_to_create) > 0:\n",
    "    print(\n",
    "        \"Parallel sentences files {} do not exist. Create these files now\".format(\n",
    "            \", \".join(map(lambda x: x[\"src_lang\"] + \"-\" + x[\"trg_lang\"], files_to_create))\n",
    "        )\n",
    "    )\n",
    "    with gzip.open(train_corpus, \"rt\", encoding=\"utf8\") as fIn:\n",
    "        reader = csv.DictReader(fIn, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "        for line in tqdm(reader, desc=\"Sentences\"):\n",
    "            for outfile in files_to_create:\n",
    "                src_text = line[outfile[\"src_lang\"]].strip()\n",
    "                trg_text = line[outfile[\"trg_lang\"]].strip()\n",
    "\n",
    "                if src_text != \"\" and trg_text != \"\":\n",
    "                    if outfile[\"devCount\"] < dev_sentences:\n",
    "                        outfile[\"devCount\"] += 1\n",
    "                        fOut = outfile[\"fDev\"]\n",
    "                    else:\n",
    "                        fOut = outfile[\"fTrain\"]\n",
    "\n",
    "                    fOut.write(\"{}\\t{}\\n\".format(src_text, trg_text))\n",
    "\n",
    "    for outfile in files_to_create:\n",
    "        outfile[\"fTrain\"].close()\n",
    "        outfile[\"fDev\"].close()\n",
    "\n",
    "\n",
    "######## Start the extension of the teacher model to multiple languages ########\n",
    "logger.info(\"Load teacher model\")\n",
    "teacher_model = SentenceTransformer(teacher_model_name)\n",
    "\n",
    "\n",
    "logger.info(\"Create student model from scratch\")\n",
    "word_embedding_model = models.Transformer(student_model_name, max_seq_length=max_seq_length)\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "student_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "print(\"Read Parallel Sentences Dataset...\")\n",
    "###### Read Parallel Sentences Dataset ######\n",
    "train_data = ParallelSentencesDataset(\n",
    "    student_model=student_model, teacher_model=teacher_model, batch_size=inference_batch_size, use_embedding_cache=True\n",
    ")\n",
    "for train_file in train_files:\n",
    "    train_data.load_data(\n",
    "        train_file, max_sentences=max_sentences_per_language, max_sentence_length=train_max_sentence_length\n",
    "    )\n",
    "\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MSELoss(model=student_model)\n",
    "\n",
    "print(\"Evaluate cross-lingual performance on different tasks...\")\n",
    "#### Evaluate cross-lingual performance on different tasks #####\n",
    "evaluators = []  # evaluators has a list of different evaluator classes we call periodically\n",
    "\n",
    "for dev_file in dev_files:\n",
    "    logger.info(\"Create evaluator for \" + dev_file)\n",
    "    src_sentences = []\n",
    "    trg_sentences = []\n",
    "    with gzip.open(dev_file, \"rt\", encoding=\"utf8\") as fIn:\n",
    "        for line in fIn:\n",
    "            splits = line.strip().split(\"\\t\")\n",
    "            if splits[0] != \"\" and splits[1] != \"\":\n",
    "                src_sentences.append(splits[0])\n",
    "                trg_sentences.append(splits[1])\n",
    "\n",
    "    # Mean Squared Error (MSE) measures the (euclidean) distance between teacher and student embeddings\n",
    "    dev_mse = evaluation.MSEEvaluator(\n",
    "        src_sentences,\n",
    "        trg_sentences,\n",
    "        name=os.path.basename(dev_file),\n",
    "        teacher_model=teacher_model,\n",
    "        batch_size=inference_batch_size,\n",
    "    )\n",
    "    evaluators.append(dev_mse)\n",
    "\n",
    "    # TranslationEvaluator computes the embeddings for all parallel sentences. It then check if the embedding of source[i] is the closest to target[i] out of all available target sentences\n",
    "    dev_trans_acc = evaluation.TranslationEvaluator(\n",
    "        src_sentences, trg_sentences, name=os.path.basename(dev_file), batch_size=inference_batch_size\n",
    "    )\n",
    "    evaluators.append(dev_trans_acc)\n",
    "\n",
    "print(\"Read cross-lingual Semantic Textual Similarity (STS) data...\")\n",
    "##### Read cross-lingual Semantic Textual Similarity (STS) data ####\n",
    "all_languages = list(set(list(source_languages) + list(target_languages)))\n",
    "sts_data = {}\n",
    "\n",
    "# Open the ZIP File of STS2017-extended.zip and check for which language combinations we have STS data\n",
    "with zipfile.ZipFile(sts_corpus) as zip:\n",
    "    filelist = zip.namelist()\n",
    "    sts_files = []\n",
    "\n",
    "    for i in range(len(all_languages)):\n",
    "        for j in range(i, len(all_languages)):\n",
    "            lang1 = all_languages[i]\n",
    "            lang2 = all_languages[j]\n",
    "            filepath = \"STS2017-extended/STS.{}-{}.txt\".format(lang1, lang2)\n",
    "            if filepath not in filelist:\n",
    "                lang1, lang2 = lang2, lang1\n",
    "                filepath = \"STS2017-extended/STS.{}-{}.txt\".format(lang1, lang2)\n",
    "\n",
    "            if filepath in filelist:\n",
    "                filename = os.path.basename(filepath)\n",
    "                sts_data[filename] = {\"sentences1\": [], \"sentences2\": [], \"scores\": []}\n",
    "\n",
    "                fIn = zip.open(filepath)\n",
    "                for line in io.TextIOWrapper(fIn, \"utf8\"):\n",
    "                    sent1, sent2, score = line.strip().split(\"\\t\")\n",
    "                    score = float(score)\n",
    "                    sts_data[filename][\"sentences1\"].append(sent1)\n",
    "                    sts_data[filename][\"sentences2\"].append(sent2)\n",
    "                    sts_data[filename][\"scores\"].append(score)\n",
    "\n",
    "for filename, data in sts_data.items():\n",
    "    test_evaluator = evaluation.EmbeddingSimilarityEvaluator(\n",
    "        data[\"sentences1\"],\n",
    "        data[\"sentences2\"],\n",
    "        data[\"scores\"],\n",
    "        batch_size=inference_batch_size,\n",
    "        name=filename,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    evaluators.append(test_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9228c1b93e1047b9aaa03537f2cf815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b615e90c67244e79995a2e7c5774f283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/11857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:27:44 - MSE evaluation (lower = better) on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 1000 steps:\n",
      "2024-03-16 20:27:44 - MSE (*100):\t21.507573\n",
      "2024-03-16 20:27:44 - Evaluating translation matching Accuracy on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 1000 steps:\n",
      "2024-03-16 20:27:47 - Accuracy src2trg: 9.10\n",
      "2024-03-16 20:27:47 - Accuracy trg2src: 7.30\n",
      "2024-03-16 20:27:47 - Save model to output/make-multilingual-en-fr-2024-03-16_20-17-09\n",
      "2024-03-16 20:39:53 - MSE evaluation (lower = better) on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 2000 steps:\n",
      "2024-03-16 20:39:53 - MSE (*100):\t3.982856\n",
      "2024-03-16 20:39:53 - Evaluating translation matching Accuracy on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 2000 steps:\n",
      "2024-03-16 20:39:57 - Accuracy src2trg: 3.10\n",
      "2024-03-16 20:39:57 - Accuracy trg2src: 2.40\n",
      "2024-03-16 20:39:57 - Save model to output/make-multilingual-en-fr-2024-03-16_20-17-09\n",
      "2024-03-16 21:00:32 - MSE evaluation (lower = better) on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 3000 steps:\n",
      "2024-03-16 21:00:32 - MSE (*100):\t2.399281\n",
      "2024-03-16 21:00:32 - Evaluating translation matching Accuracy on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 3000 steps:\n",
      "2024-03-16 21:00:36 - Accuracy src2trg: 2.00\n",
      "2024-03-16 21:00:36 - Accuracy trg2src: 2.50\n",
      "2024-03-16 21:00:36 - Save model to output/make-multilingual-en-fr-2024-03-16_20-17-09\n",
      "2024-03-16 21:27:30 - MSE evaluation (lower = better) on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 4000 steps:\n",
      "2024-03-16 21:27:30 - MSE (*100):\t2.180654\n",
      "2024-03-16 21:27:30 - Evaluating translation matching Accuracy on talks-en-fr-dev.tsv.gz dataset in epoch 0 after 4000 steps:\n",
      "2024-03-16 21:27:36 - Accuracy src2trg: 2.80\n",
      "2024-03-16 21:27:36 - Accuracy trg2src: 1.50\n",
      "2024-03-16 21:27:36 - Save model to output/make-multilingual-en-fr-2024-03-16_20-17-09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\notebooks\\trainCustomST.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m student_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     train_objectives\u001b[39m=\u001b[39;49m[(train_dataloader, train_loss)],\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     evaluator\u001b[39m=\u001b[39;49mevaluation\u001b[39m.\u001b[39;49mSequentialEvaluator(evaluators, main_score_function\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m scores: np\u001b[39m.\u001b[39;49mmean(scores)),\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     warmup_steps\u001b[39m=\u001b[39;49mnum_warmup_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     evaluation_steps\u001b[39m=\u001b[39;49mnum_evaluation_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     output_path\u001b[39m=\u001b[39;49moutput_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     save_best_model\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     optimizer_params\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m2e-5\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1e-6\u001b[39;49m},\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification/notebooks/trainCustomST.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:964\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[0;32m    962\u001b[0m     skip_scheduler \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mget_scale() \u001b[39m!=\u001b[39m scale_before_step\n\u001b[0;32m    963\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 964\u001b[0m     loss_value \u001b[39m=\u001b[39m loss_model(features, labels)\n\u001b[0;32m    965\u001b[0m     loss_value\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    966\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(loss_model\u001b[39m.\u001b[39mparameters(), max_grad_norm)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\sentence_transformers\\losses\\MSELoss.py:64\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, sentence_features, labels)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[39mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[1;32m---> 64\u001b[0m     rep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(sentence_features[\u001b[39m0\u001b[39;49m])[\u001b[39m\"\u001b[39m\u001b[39msentence_embedding\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fct(rep, labels)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[0;32m     96\u001b[0m     trans_features[\u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 98\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrans_features, return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     99\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m\"\u001b[39m: output_tokens, \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m: features[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]})\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:843\u001b[0m, in \u001b[0;36mGPTNeoModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    833\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    834\u001b[0m         block\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    835\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    840\u001b[0m         output_attentions,\n\u001b[0;32m    841\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[0;32m    844\u001b[0m         hidden_states,\n\u001b[0;32m    845\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    846\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    847\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    848\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    849\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    850\u001b[0m     )\n\u001b[0;32m    852\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    853\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:570\u001b[0m, in \u001b[0;36mGPTNeoBlock.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    568\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m    569\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[1;32m--> 570\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[0;32m    571\u001b[0m     hidden_states,\n\u001b[0;32m    572\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    573\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    574\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    575\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    576\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    577\u001b[0m )\n\u001b[0;32m    578\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    579\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:522\u001b[0m, in \u001b[0;36mGPTNeoAttention.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    514\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    515\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    521\u001b[0m ):\n\u001b[1;32m--> 522\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    523\u001b[0m         hidden_states,\n\u001b[0;32m    524\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    525\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    526\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    527\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    528\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    529\u001b[0m     )\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:283\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     present \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attn(query, key, value, attention_mask, head_mask)\n\u001b[0;32m    285\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_heads(attn_output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[0;32m    286\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj(attn_output)\n",
      "File \u001b[1;32mg:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:236\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention._attn\u001b[1;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[0;32m    233\u001b[0m mask_value \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfinfo(attn_weights\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mmin\n\u001b[0;32m    234\u001b[0m \u001b[39m# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m mask_value \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(mask_value, dtype\u001b[39m=\u001b[39;49mattn_weights\u001b[39m.\u001b[39;49mdtype)\u001b[39m.\u001b[39;49mto(attn_weights\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    237\u001b[0m attn_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(causal_mask, attn_weights, mask_value)\n\u001b[0;32m    239\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[39m# Apply the attention mask\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "student_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluation.SequentialEvaluator(evaluators, main_score_function=lambda scores: np.mean(scores)),\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=num_warmup_steps,\n",
    "    evaluation_steps=num_evaluation_steps,\n",
    "    output_path=output_path,\n",
    "    save_best_model=True,\n",
    "    optimizer_params={\"lr\": 2e-5, \"eps\": 1e-6},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "# Push to the Hub\n",
    "student_model.save_to_hub(\"paraphrase-mpnet-base-v2-fr-en\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
