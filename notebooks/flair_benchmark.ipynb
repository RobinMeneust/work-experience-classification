{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test Flair performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if CUDA is available and use it if it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///G:/CYTech/ING2/ProjetLinkedin/2024_02_25/linkedin-work-experience-classification\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: few-shot-benchmark\n",
      "  Attempting uninstall: few-shot-benchmark\n",
      "    Found existing installation: few-shot-benchmark 0.1.0\n",
      "    Uninstalling few-shot-benchmark-0.1.0:\n",
      "      Successfully uninstalled few-shot-benchmark-0.1.0\n",
      "  Running setup.py develop for few-shot-benchmark\n",
      "Successfully installed few-shot-benchmark-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -e ..\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import disable_progress_bar\n",
    "disable_progress_bar() # Disable the \"Map\" progress bar during the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the dataset\n",
    "\n",
    "This dataset is not on the GitHub repository.\n",
    "It's composed of work experienced fetched from LinkedIn and labelled between 0 and 4 (0 if it's not related to AI and 4 if it is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_pickle(r'../data/7587_corrige.pkl')\n",
    "subset = dataFrame[['jobTitle', 'description', 'label']].copy()\n",
    "\n",
    "subset.reset_index(drop=True, inplace=True)\n",
    "subset.replace('', np.nan, inplace=True)\n",
    "subset.dropna(inplace=True)\n",
    "\n",
    "subset['text'] = subset['jobTitle'] + ' ' + subset['description']\n",
    "subset = subset[['text','label']]\n",
    "subset_label_transform = subset.copy()\n",
    "\n",
    "subset_label_transform['label'] = np.where((subset_label_transform[\"label\"] < 3) | (subset_label_transform[\"label\"].isna()), 0, 1)\n",
    "subset_label_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset in two subsets : the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.utility import split_dataset\n",
    "train_set, test_set = split_dataset(subset_label_transform, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat this process with diffent ways of cleaning the data\n",
    "\n",
    "Here instead of considering Nan, 0, 1 and 2 as not being an AI experience and 3 and 4 as being one, we consider :\n",
    "\n",
    "- not AI = 0 and 1 and AI = 3 and 4 (we drop the examples with the label NaN or 2)\n",
    "- not AI = 0 and AI = 4 (we drop the examples with the label NaN, 1, 2 or 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_label_transform_likely_labels = subset.copy()\n",
    "subset_label_transform_likely_labels.replace({2: np.nan}, inplace=True)\n",
    "subset_label_transform_likely_labels.dropna(inplace=True)\n",
    "subset_label_transform_likely_labels['label'] = np.where((subset_label_transform_likely_labels[\"label\"] < 3), 0, 1)\n",
    "\n",
    "subset_label_transform_sure_labels = subset.copy()\n",
    "subset_label_transform_sure_labels.replace({1: np.nan, 2: np.nan, 3: np.nan}, inplace=True)\n",
    "subset_label_transform_sure_labels.dropna(inplace=True)\n",
    "subset_label_transform_sure_labels['label'] = np.where((subset_label_transform_sure_labels[\"label\"] == 0), 0, 1)\n",
    "\n",
    "# We keep the full test set\n",
    "train_set_likely_labels, _ = split_dataset(subset_label_transform_likely_labels, 0.2) \n",
    "train_set_sure_labels, _ = split_dataset(subset_label_transform_sure_labels, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "src_dir = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "\n",
    "# Add 'src' directory to sys.path if it's not already there\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.utility import save_to_json\n",
    "from benchmark.tests import n_shot_tests\n",
    "from benchmark.train_eval_task import flair_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-shots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default SetFit uses the oversampling strategy and the Cosine Similarity loss. For instance if we have 8 positive and 8 negative examples then we have:\n",
    "\n",
    "|   | Y | Y | Y | Y | Y | Y | Y | Y | N | N | N | N | N | N | N | N |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| Y | + | + | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   | + | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   |   | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   |   |   | + | - | - | - | - | - | - | - | - |\n",
    "| N |   |   |   |   |   |   |   |   | + | + | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   | + | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   |   | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   | + |\n",
    "\n",
    "- P = 2 * (8 + 7 + 6 + 5 + 4 + 3 + 2 + 1) \t= 72\n",
    "- N = 8 * 8 = 64 -> + 8 duplications \t\t= 72\n",
    "- Total = 72 + 72 = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_shot\": [1, 2, 4, 6, 10],\n",
    "    \"n_iter\": 5,\n",
    "    \"n_max_iter_per_shot\": 5,\n",
    "    \"model\": \"flair-base\",\n",
    "    \"loss\": \"CrossEntropyLoss\"\n",
    "}\n",
    "\n",
    "results, run_times = n_shot_tests(params, train_set, test_set, few_shot_model_f1_function=flair_f1_score)\n",
    "\n",
    "save_to_json(results, run_times, params,  r'../results/flair/n_shot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
