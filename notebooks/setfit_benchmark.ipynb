{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test SetFit performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change logs settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import CosineSimilarityLoss, BatchAllTripletLoss, BatchHardTripletLossDistanceFunction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Disable some logs because there were too many messages during the tests\n",
    "# logging.disable(logging.INFO)\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from datasets import disable_progress_bar\n",
    "disable_progress_bar() # Disable the \"Map\" progress bar during the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the dataset\n",
    "\n",
    "This dataset is not on the GitHub repository.\n",
    "It's composed of work experienced fetched from LinkedIn and labelled between 0 and 4 (0 if it's not related to AI and 4 if it is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stagiaire ingénieur en intelligence artificiel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stagiaire en développement logiciel. Développe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stagiaire en développement Web. Création et év...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stagiaire en développement Web. Portage d’une ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Développeur Data / IA. Développement d'applica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11281</th>\n",
       "      <td>Opérateur production. Montage de transmission ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11282</th>\n",
       "      <td>Opérateur production. Montage de transmission ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11283</th>\n",
       "      <td>Technicien réparation informatique. Reparation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>Technicien réparation. Reparation &amp; maintenanc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11286</th>\n",
       "      <td>Développeur web freelance. Webdesign &amp; Infogra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "2      Stagiaire ingénieur en intelligence artificiel...      1\n",
       "3      Stagiaire en développement logiciel. Développe...      0\n",
       "4      Stagiaire en développement Web. Création et év...      0\n",
       "5      Stagiaire en développement Web. Portage d’une ...      0\n",
       "6      Développeur Data / IA. Développement d'applica...      1\n",
       "...                                                  ...    ...\n",
       "11281  Opérateur production. Montage de transmission ...      0\n",
       "11282  Opérateur production. Montage de transmission ...      0\n",
       "11283  Technicien réparation informatique. Reparation...      0\n",
       "11284  Technicien réparation. Reparation & maintenanc...      0\n",
       "11286  Développeur web freelance. Webdesign & Infogra...      0\n",
       "\n",
       "[5167 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = pd.read_pickle(r'../data/7587_corrige.pkl')\n",
    "subset = dataFrame[['jobTitle', 'description', 'label']].copy()\n",
    "\n",
    "subset.reset_index(drop=True, inplace=True)\n",
    "subset.replace('', np.nan, inplace=True) # drop NaN labels, job titles and descriptions\n",
    "subset.dropna(inplace=True)\n",
    "\n",
    "subset['text'] = subset['jobTitle'] + '. ' + subset['description']\n",
    "subset = subset[['text','label']]\n",
    "subset_label_transform = subset.copy()\n",
    "\n",
    "subset_label_transform['label'] = np.where((subset_label_transform[\"label\"] < 3), 0, 1)\n",
    "subset_label_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset in two subsets : the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.utility import split_dataset\n",
    "train_set, test_set = split_dataset(subset_label_transform, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\robin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from benchmark.utility import save_to_json\n",
    "from benchmark.tests import n_shot_tests, input_length_tests, distance_tests, loss_tests, language_tests, model_tests, num_epochs_tests, constant_params_tests, data_augmentation_tests\n",
    "from benchmark.train_eval_task import setfit_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-shots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default SetFit uses the oversampling strategy and the Cosine Similarity loss. For instance if we have 8 positive and 8 negative examples then we have:\n",
    "\n",
    "|   | Y | Y | Y | Y | Y | Y | Y | Y | N | N | N | N | N | N | N | N |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| Y | + | + | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   | + | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   |   | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   |   |   | + | - | - | - | - | - | - | - | - |\n",
    "| N |   |   |   |   |   |   |   |   | + | + | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   | + | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   |   | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   | + |\n",
    "\n",
    "- P = 2 * (8 + 7 + 6 + 5 + 4 + 3 + 2 + 1) \t= 72\n",
    "- N = 8 * 8 = 64 -> + 8 duplications \t\t= 72\n",
    "- Total = 72 + 72 = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_shot\": [1, 2, 4, 6, 10, 20, 40, 60, 100],\n",
    "    \"n_iter\": 10,\n",
    "    \"n_max_iter_per_shot\": 10,\n",
    "    \"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    \"loss\": BatchAllTripletLoss\n",
    "}\n",
    "\n",
    "results, train_times, eval_times = n_shot_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/n_shot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_length_range\": [[0,5],[5,25],[25,50],[50,100],[100,200],[200,350]],\n",
    "    # [[6,10],[10,15],[15,20],[20,30], [6,15], [15,30], [6,20], [10,30], [6,30]],\n",
    "    # [[0,5],[5,10], [10,50], [50,100],[100,200],[200,350]],\n",
    "    # [[0,9],[1,9],[2,9],[3,9],[4,9],[5,9],[6,9],[7,9],[8,9],[9,9]],\n",
    "    # [[0,9],[9,100],[9,350],[100,350],[0,350]],\n",
    "\t# [[8,50],[8,100],[8,150],[8,200],[8,250],[8,300],[8,350]],\n",
    "\t# [[7,350],[8,350],[9,350],[10,350]],\n",
    "    # [[0,3],[0,4],[0,5],[0,6],[0,7],[0,8],[0,9],[0,10]],\n",
    "    # [[0,5],[0,10],[0,100],[6,100],[ 200,350]],\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"loss\": BatchAllTripletLoss\n",
    "}\n",
    "\n",
    "results, train_times, eval_times = input_length_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/input_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"distance\": {\n",
    "\t\t\"Cosine\":BatchHardTripletLossDistanceFunction.cosine_distance,\n",
    "\t\t\"Euclidian\": BatchHardTripletLossDistanceFunction.eucledian_distance, # it's really \"eucledian\" and not \"euclidian\" in the module sentence_transformers\n",
    "\t},\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "}\n",
    "\n",
    "\n",
    "results, train_times, eval_times = distance_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss (pair-wise or Triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"loss\": {\"Pair-wise\":CosineSimilarityLoss, \"Triplet\":BatchAllTripletLoss}\n",
    "}\n",
    "\n",
    "results, train_times, eval_times = loss_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"lang\": ['fr','en'],\n",
    "\t\"n_iter\": 50,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"loss\": BatchAllTripletLoss\n",
    "}\n",
    "\n",
    "results, train_times, eval_times = language_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/language')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "\t\"model\": {\n",
    "\t\t# \"instructor-large\":\"hkunlp/instructor-large\",\n",
    "\t\t\"GIST-small-Embedding-v0\":\"avsolatorio/GIST-small-Embedding-v0\",\n",
    "\t\t\"gte-tiny\":\"TaylorAI/gte-tiny\",\n",
    "\t\t# \"all-mpnet-base-v2-table\":\"deepset/all-mpnet-base-v2-table\",\n",
    "  \t\t\"paraphrase-mpnet-base-v2\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\t# \"all-mpnet-base-v2\":\"sentence-transformers/all-mpnet-base-v2\",\n",
    "\t}\n",
    "}\n",
    "results, run_train_times, eval_timestimes = model_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"num_epochs\": [(8,1),(8,2),(8,4),(8,8),(8,10),(8,20),(8,30),(8,40)], \n",
    "\t# [(1,1),(2,1),(4,1),(8,1),(16,1),(32,1),(64,1)], \n",
    "\t# [(1,1),(1,2),(1,4),(1,8),(1,12),(1,16),(1,20),(1,25),(1,30)],\n",
    "}\n",
    "\n",
    "results, train_times, eval_times = num_epochs_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/num_epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling\n",
    "\n",
    "Run multiple tests with different training sets but the same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 / 50 Estimated remaining time: ?\n",
      "0 failed CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 18.26 GiB is allocated by PyTorch, and 39.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 2 / 50 Estimated remaining time: 6 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3 / 50 Estimated remaining time: 41 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 failed CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 1.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 4 / 50 Estimated remaining time: 37 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5 / 50 Estimated remaining time: 54 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6 / 50 Estimated remaining time: 64 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7 / 50 Estimated remaining time: 66 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8 / 50 Estimated remaining time: 66 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9 / 50 Estimated remaining time: 66 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10 / 50 Estimated remaining time: 67 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 failed CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 17.46 GiB is allocated by PyTorch, and 703.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 11 / 50 Estimated remaining time: 61 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12 / 50 Estimated remaining time: 60 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 failed CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 17.74 GiB is allocated by PyTorch, and 438.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 13 / 50 Estimated remaining time: 55 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14 / 50 Estimated remaining time: 55 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15 / 50 Estimated remaining time: 53 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 failed CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 17.71 GiB is allocated by PyTorch, and 612.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 16 / 50 Estimated remaining time: 50 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 17 / 50 Estimated remaining time: 48 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 18 / 50 Estimated remaining time: 45 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 19 / 50 Estimated remaining time: 44 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20 / 50 Estimated remaining time: 43 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 21 / 50 Estimated remaining time: 41 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 failed CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 18.26 GiB is allocated by PyTorch, and 39.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 22 / 50 Estimated remaining time: 38 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 23 / 50 Estimated remaining time: 37 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24 / 50 Estimated remaining time: 36 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 25 / 50 Estimated remaining time: 35 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 26 / 50 Estimated remaining time: 33 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 failed CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 17.49 GiB is allocated by PyTorch, and 838.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 27 / 50 Estimated remaining time: 31 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 28 / 50 Estimated remaining time: 30 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 29 / 50 Estimated remaining time: 29 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 30 / 50 Estimated remaining time: 28 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 31 / 50 Estimated remaining time: 27 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 32 / 50 Estimated remaining time: 26 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 33 / 50 Estimated remaining time: 24 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 34 / 50 Estimated remaining time: 23 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 35 / 50 Estimated remaining time: 21 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 36 / 50 Estimated remaining time: 20 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 failed CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 37 / 50 Estimated remaining time: 18 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 38 / 50 Estimated remaining time: 17 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 39 / 50 Estimated remaining time: 16 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 40 / 50 Estimated remaining time: 14 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 failed CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 17.56 GiB is allocated by PyTorch, and 759.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 41 / 50 Estimated remaining time: 13 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 42 / 50 Estimated remaining time: 11 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 43 / 50 Estimated remaining time: 10 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 44 / 50 Estimated remaining time: 9 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 failed CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 18.07 GiB is allocated by PyTorch, and 253.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 45 / 50 Estimated remaining time: 8 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 failed CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 17.27 GiB is allocated by PyTorch, and 935.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 46 / 50 Estimated remaining time: 6 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 failed CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 18.26 GiB is allocated by PyTorch, and 39.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Step: 47 / 50 Estimated remaining time: 5 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 48 / 50 Estimated remaining time: 4 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 49 / 50 Estimated remaining time: 3 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50 / 50 Estimated remaining time: 1 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\CYTech\\ING2\\ProjetLinkedin\\2024_02_25\\linkedin-work-experience-classification\\.venv\\lib\\site-packages\\setfit\\data.py:154: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.apply(lambda x: x.sample(min(num_samples, len(x)), random_state=seed))\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 10,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"loss\": CosineSimilarityLoss,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "}\n",
    "\n",
    "results, train_times, eval_times = constant_params_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/data_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_shot\": 8,\n",
    "    \"n_iter\": 50,\n",
    "    \"loss\": CosineSimilarityLoss,\n",
    "    \"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    \"data_augmentation_ratio\": 1.3, # + 30 %\n",
    "    \"data_augmentation_strategy\":[\"none\",\"swapping_inter\", \"back_translation\", \"synonym_replacement\", \"crossover\"],\n",
    "    \"strategy_params\": {\n",
    "        \"n_points_crossover\": 2,\n",
    "        \"modification_rate\": 0.5,\n",
    "    }\n",
    "}\n",
    "\n",
    "results, train_times, eval_times = data_augmentation_tests(params, train_set, test_set, few_shot_model_f1_function=setfit_f1_score)\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/data_augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset label selection\n",
    "\n",
    "Here instead of considering Nan, 0, 1 and 2 as not being an AI experience and 3 and 4 as being one, we consider :\n",
    "\n",
    "- not AI = 0 and 1 and AI = 3 and 4 (we drop the examples with the label NaN or 2)\n",
    "- not AI = 0 and AI = 4 (we drop the examples with the label NaN, 1, 2 or 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_label_transform_likely_labels = subset.copy()\n",
    "subset_label_transform_likely_labels.replace({2: np.nan}, inplace=True)\n",
    "subset_label_transform_likely_labels.dropna(inplace=True)\n",
    "subset_label_transform_likely_labels['label'] = np.where((subset_label_transform_likely_labels[\"label\"] < 3), 0, 1)\n",
    "\n",
    "subset_label_transform_sure_labels = subset.copy()\n",
    "subset_label_transform_sure_labels.replace({1: np.nan, 2: np.nan, 3: np.nan}, inplace=True)\n",
    "subset_label_transform_sure_labels.dropna(inplace=True)\n",
    "subset_label_transform_sure_labels['label'] = np.where((subset_label_transform_sure_labels[\"label\"] == 0), 0, 1)\n",
    "\n",
    "# We keep the full test set\n",
    "train_set_likely_labels, _ = split_dataset(subset_label_transform_likely_labels, 0.2) \n",
    "train_set_sure_labels, _ = split_dataset(subset_label_transform_sure_labels, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_shot\": 10,\n",
    "    \"n_iter\": 50,\n",
    "    \"loss\": CosineSimilarityLoss,\n",
    "    \"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "}\n",
    "\n",
    "tested_training_sets = {\n",
    "    \"all_labels\": train_set,\n",
    "    \"likely_labels\":train_set_likely_labels,\n",
    "    \"sure_labels\":train_set_sure_labels,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "train_times = {}\n",
    "eval_times = {}\n",
    "progress = 0\n",
    "progress_end = len(tested_training_sets)\n",
    "\n",
    "for training_set_key, training_set_data in tested_training_sets.items():\n",
    "    print(\"Test: \", progress,\"/\",progress_end)\n",
    "    temp_results, temp_train_times, temp_eval_times = constant_params_tests(params, training_set_data, test_set, setfit_f1_score)\n",
    "    results[training_set_key] = temp_results[\"all\"]\n",
    "    train_times[training_set_key] = temp_train_times[\"all\"]\n",
    "    eval_times[training_set_key] = temp_eval_times[\"all\"]\n",
    "\n",
    "params[\"training_set\"] = list(tested_training_sets.keys())\n",
    "save_to_json(results, train_times, eval_times, params,  r'../results/setfit/training_set_labels_restriction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
