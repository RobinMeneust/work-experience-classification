{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test SetFit performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataFrame = pd.read_pickle(r'../data/7587_corrige.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stagiaire ingénieur en intelligence artificiel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stagiaire en développement logiciel Développem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stagiaire en développement Web Création et évo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stagiaire en développement Web Portage d’une a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Développeur Data / IA Développement d'applicat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11281</th>\n",
       "      <td>Opérateur production Montage de transmission a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11282</th>\n",
       "      <td>Opérateur production Montage de transmission a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11283</th>\n",
       "      <td>Technicien réparation informatique Reparation ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>Technicien réparation Reparation &amp; maintenance...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11286</th>\n",
       "      <td>Développeur web freelance Webdesign &amp; Infographie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "2      Stagiaire ingénieur en intelligence artificiel...      1\n",
       "3      Stagiaire en développement logiciel Développem...      0\n",
       "4      Stagiaire en développement Web Création et évo...      0\n",
       "5      Stagiaire en développement Web Portage d’une a...      0\n",
       "6      Développeur Data / IA Développement d'applicat...      1\n",
       "...                                                  ...    ...\n",
       "11281  Opérateur production Montage de transmission a...      0\n",
       "11282  Opérateur production Montage de transmission a...      0\n",
       "11283  Technicien réparation informatique Reparation ...      0\n",
       "11284  Technicien réparation Reparation & maintenance...      0\n",
       "11286  Développeur web freelance Webdesign & Infographie      0\n",
       "\n",
       "[5167 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = dataFrame[['jobTitle', 'description', 'label']].copy()\n",
    "\n",
    "subset.reset_index(drop=True, inplace=True)\n",
    "subset.replace('', np.nan, inplace=True)\n",
    "subset.dropna(inplace=True)\n",
    "\n",
    "subset['text'] = subset['jobTitle'] + ' ' + subset['description']\n",
    "subset = subset[['text','label']]\n",
    "subset_label_transform = subset.copy() # to test with different\n",
    "\n",
    "subset_label_transform['label'] = np.where((subset_label_transform[\"label\"] < 3) | (subset_label_transform[\"label\"].isna()), 0, 1)\n",
    "subset_label_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in two: training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, disable_progress_bar\n",
    "disable_progress_bar() # Disable \"Map\" progress bar in the tests\n",
    "\n",
    "def split_train_test(dataset, ratio):\n",
    "    test_set = dataset.sample(frac = ratio, random_state=42)\n",
    "    train_set = dataset.drop(test_set.index)\n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = split_train_test(subset_label_transform, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another train set and data set with different initial label values selected (0,1 and 3 and 4 only) and (0,4 only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_label_transform_likely_labels = subset.copy()\n",
    "subset_label_transform_likely_labels.replace({2: np.nan}, inplace=True)\n",
    "subset_label_transform_likely_labels.dropna(inplace=True)\n",
    "subset_label_transform_likely_labels['label'] = np.where((subset_label_transform_likely_labels[\"label\"] < 3), 0, 1)\n",
    "\n",
    "subset_label_transform_sure_labels = subset.copy()\n",
    "subset_label_transform_sure_labels.replace({1: np.nan, 2: np.nan, 3: np.nan}, inplace=True)\n",
    "subset_label_transform_sure_labels.dropna(inplace=True)\n",
    "subset_label_transform_sure_labels['label'] = np.where((subset_label_transform_sure_labels[\"label\"] == 0), 0, 1)\n",
    "\n",
    "# We keep the full test set\n",
    "train_set_likely_labels, _ = split_train_test(subset_label_transform_likely_labels, 0.2) \n",
    "train_set_sure_labels, _ = split_train_test(subset_label_transform_sure_labels, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to test different hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sentence_transformers.losses import CosineSimilarityLoss, BatchAllTripletLoss, BatchHardTripletLossDistanceFunction\n",
    "from transformers import PrinterCallback, ProgressCallback\n",
    "from setfit import Trainer, TrainingArguments, sample_dataset, SetFitModel\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "\n",
    "def save_to_json(object, folder_path):\n",
    "\t# Create folder if it doesn't exist\n",
    "\tif not os.path.exists(folder_path):\n",
    "\t\tos.makedirs(folder_path)\n",
    "\t# Generate file name\n",
    "\tdate = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\tfile_name = folder_path+'/'+str(date)+\".json\"\n",
    "\n",
    "\t# Create file and save data\n",
    "\twith open(file_name, 'w') as file:\n",
    "\t\tjson.dump(object, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_model(model_name, use_differentiable_head=False):\n",
    "    model = SetFitModel.from_pretrained(model_name, use_differentiable_head=use_differentiable_head)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return model.to('cuda')\n",
    "\n",
    "def init_trainer(model, loss, train_dataset, test_dataset, distance_metric = None, classification_head = None, num_epochs = None, batch_size = None, head_learning_rate = None):\n",
    "    if distance_metric is None:\n",
    "        distance_metric = BatchHardTripletLossDistanceFunction.cosine_distance # default value for SetFit\n",
    "    if classification_head is None:\n",
    "        classification_head = BatchHardTripletLossDistanceFunction.cosine_distance # default value for SetFit\n",
    "    \n",
    "    # Number of epochs to use for contrastive learning (for the transformer and for the classification head)\n",
    "    if num_epochs is None:\n",
    "        num_epochs = (1,16) \n",
    "    if batch_size is None:\n",
    "        batch_size = (16,2)\n",
    "    \n",
    "    if head_learning_rate is None:\n",
    "        head_learning_rate = 1e-2\n",
    "    \n",
    "    trainer_arguments = TrainingArguments(\n",
    "        show_progress_bar=False,\n",
    "        loss=loss,\n",
    "        distance_metric=distance_metric,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "\t\thead_learning_rate=head_learning_rate,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=trainer_arguments,\n",
    "        metric='f1',\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset\n",
    "    )\n",
    "    \n",
    "    # Disable some logs because there were too many messages during the tests\n",
    "    trainer.pop_callback(PrinterCallback)\n",
    "    trainer.pop_callback(ProgressCallback)\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "def setfit_f1_score(train_set, test_set, model_name, loss, distance_metric=None, classification_head=None, num_epochs = None, batch_size = None, head_learning_rate = None):\n",
    "    if len(train_set) <= 1 or len(test_set) <= 1:\n",
    "        raise Exception\n",
    "    \n",
    "    model = get_transformer_model(model_name, (not (num_epochs is None)) and num_epochs[1]>1)\n",
    "    trainer = init_trainer(model, loss, train_set, test_set, distance_metric, classification_head, num_epochs, batch_size, head_learning_rate)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    run_time = time.time() - start_time\n",
    "    \n",
    "    metrics = trainer.evaluate()\n",
    "    \n",
    "    del model\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return metrics['f1'], run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def filter_lang(df, lang):\n",
    "    indices = []\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            l = detect(df.iloc[i][\"text\"])\n",
    "            if l == lang:\n",
    "                indices.append(i)\n",
    "        except:\"\"\n",
    "    \n",
    "    return df.iloc[indices]\n",
    "\n",
    "def filter_dataset(data, min_text_length=None, max_text_length=None, lang=None):\n",
    "    if min_text_length is None:\n",
    "        if max_text_length is None:\n",
    "            filtered_data = data\n",
    "        else:\n",
    "            filtered_data = data[data['text'].str.split().apply(len) <= max_text_length]\n",
    "    else:\n",
    "        if max_text_length is None:\n",
    "            filtered_data = data[data['text'].str.split().apply(len) >= min_text_length]\n",
    "        else:\n",
    "            filtered_data = data[data['text'].str.split().apply(len).between(min_text_length, max_text_length)]\n",
    "            \n",
    "    if not (lang is None):\n",
    "        filtered_data = filter_lang(filtered_data, lang)\n",
    "           \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some logs because there were too many messages during the tests\n",
    "# logging.disable(logging.INFO)\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_shot_tests(params, train_set, test_set):\n",
    "\tn_values = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tn_max_iter_per_shot = params[\"n_max_iter_per_shot\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    "    \n",
    "\tn_values_max = np.max(n_values)\n",
    "\n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\tfor n_shot in n_values:\n",
    "\t\tresults[n_shot] = []\n",
    "\t\trun_times[n_shot] = []\n",
    "\t\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * ((len(n_values)-1)*n_max_iter_per_shot + 1)\n",
    " \n",
    "\t# Repeat the tests multiple times because F1-score variations might be due to the examples chosen and not the input length of those examples\n",
    "\tfor i in range(n_iter):\n",
    "\t\t# Use the same subset of the dataset for all of the tests in the following loop\n",
    "\t\tif not (input_length_range is None):\n",
    "\t\t\tnew_train_set = filter_dataset(train_set, input_length_range[0], input_length_range[1])\n",
    "\t\telse:\n",
    "\t\t\tnew_train_set = train_set\n",
    "\t\tnew_train_set = new_train_set.sample(frac = 1, random_state=i*47).groupby('label').head(n_values_max)\n",
    "\t\tnew_train_set = Dataset.from_pandas(new_train_set, split=\"train\")\n",
    "\t\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    "\n",
    "\t\tfor n_shot in n_values:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tn_iter_shot = n_max_iter_per_shot if n_shot < n_values_max else 1\n",
    "\t\t\t\tfor i_shot in range(n_iter_shot):\n",
    "\t\t\t\t\tprogress += 1\n",
    "\t\t\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "     \n",
    "\t\t\t\t\ttrain_set_n_shot = sample_dataset(new_train_set, label_column=\"label\", num_samples=n_shot, seed=47*n_shot + 3*i_shot, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\t\t\tf1_score, run_time = setfit_f1_score(train_set_n_shot, new_test_set, model, loss)\n",
    "\t\t\t\t\tresults[n_shot].append(f1_score)\n",
    "\t\t\t\t\trun_times[n_shot].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(n_shot, \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_length_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tlen_values = params[\"input_length_range\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    "    \n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    "\n",
    "\tfor i in range(len(len_values)):\n",
    "\t\tkey = f\"[{len_values[i][0]},{len_values[i][1]}]\"\n",
    "\t\tresults[key] = []\n",
    "\t\trun_times[key] = []\n",
    "\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * len(len_values)\n",
    " \n",
    "\t# Repeat the tests multiple times because F1-score variations might be due to the examples chosen and not the input length of those examples\n",
    "\tfor iter in range(n_iter):\n",
    "\t\tfor i in range(len(len_values)):\n",
    "\t\t\tkey = f\"[{len_values[i][0]},{len_values[i][1]}]\"\n",
    "\t\t\ttry:\n",
    "\t\t\t\tprogress += 1\n",
    "\t\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "    \n",
    "\t\t\t\tnew_train_set = filter_dataset(train_set, len_values[i][0], len_values[i][1])\n",
    "\t\t\t\tnew_train_set = Dataset.from_pandas(new_train_set, split=\"train\")\n",
    "\t\t\t\tnew_train_set = sample_dataset(new_train_set, label_column=\"label\", num_samples=n_shot, seed=47*iter)\n",
    "\t\t\t\tf1_score, run_time = setfit_f1_score(new_train_set, new_test_set, model, loss, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\t\tresults[key].append(f1_score)\n",
    "\t\t\t\trun_times[key].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(key, \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tdistances = params[\"distance\"]\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    "\n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\tfor key in distances.keys():\n",
    "\t\tresults[key] = []\n",
    "\t\trun_times[key] = []\n",
    "\n",
    "\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    " \n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * (len(distances))\n",
    "\n",
    "\tfor i in range(n_iter):\n",
    "\t\tif not (input_length_range is None):\n",
    "\t\t\tnew_train_set = filter_dataset(train_set, input_length_range[0], input_length_range[1])\n",
    "\t\telse:\n",
    "\t\t\tnew_train_set = train_set\n",
    "\t\tnew_train_set = Dataset.from_pandas(new_train_set, split=\"train\")\n",
    "\t\tnew_train_set = sample_dataset(new_train_set, label_column=\"label\", num_samples=n_shot, seed=47*i)\n",
    "\t\t\n",
    "\t\tfor key in distances.keys():\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "   \n",
    "\t\t\ttry:\n",
    "\t\t\t\tf1_score, run_time = setfit_f1_score(new_train_set, new_test_set, model, loss, distances[key], num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\t\tresults[key].append(f1_score)\n",
    "\t\t\t\trun_times[key].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(key, \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tlosses = params[\"loss\"]\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    " \n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\tfor key in losses.keys():\n",
    "\t\tresults[key] = []\n",
    "\t\trun_times[key] = []\n",
    "\n",
    "\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    " \n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * (len(losses))\n",
    "\n",
    "\tfor i in range(n_iter):\n",
    "\t\tif not (input_length_range is None):\n",
    "\t\t\tnew_train_set = filter_dataset(train_set, input_length_range[0], input_length_range[1])\n",
    "\t\telse:\n",
    "\t\t\tnew_train_set = train_set\n",
    "\t\tnew_train_set = Dataset.from_pandas(new_train_set, split=\"train\")\n",
    "\t\tnew_train_set = sample_dataset(new_train_set, label_column=\"label\", num_samples=n_shot, seed=47*i)\n",
    "\t\t\n",
    "\t\tfor key in losses.keys():\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "   \n",
    "\t\t\ttry:\n",
    "\t\t\t\tf1_score, run_time = setfit_f1_score(new_train_set, new_test_set, model, losses[key], num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\t\tresults[key].append(f1_score)\n",
    "\t\t\t\trun_times[key].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(key, \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tlanguages = params[\"lang\"]\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    " \n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\n",
    "\tfor key in languages:\n",
    "\t\tresults[key] = []\n",
    "\t\trun_times[key] = []\n",
    "\tresults['all'] = []\n",
    "\trun_times['all'] = []\n",
    " \n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * (len(languages) + 1)\n",
    " \n",
    "\tfor i in range(n_iter):\n",
    "\t\ttemp_train_set_panda = {}\n",
    "\t\ttemp_test_set_panda = {}\n",
    "\n",
    "\t\tfor key in languages:\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "   \n",
    "\t\t\ttemp_train_set_panda[key] = filter_dataset(train_set, lang=key)\n",
    "\t\t\tif not (input_length_range is None):\n",
    "\t\t\t\ttemp_train_set_panda[key] = filter_dataset(temp_train_set_panda[key], input_length_range[0], input_length_range[1])\n",
    "\t\t\ttemp_train_set = Dataset.from_pandas(temp_train_set_panda[key], split=\"train\")\n",
    "\t\t\ttemp_train_set = sample_dataset(temp_train_set, label_column=\"label\", num_samples=n_shot, seed=47*i)\n",
    "   \n",
    "\t\t\ttemp_test_set_panda[key] = filter_dataset(test_set, lang=key)\n",
    "\t\t\ttemp_test_set = Dataset.from_pandas(temp_test_set_panda[key], split=\"test\")\n",
    "\t\t\ttry:\n",
    "\t\t\t\tf1_score, run_time = setfit_f1_score(temp_train_set, temp_test_set, model, loss, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\t\tresults[key].append(f1_score)\n",
    "\t\t\t\trun_times[key].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(key, \"failed\", str(err))\n",
    "\t\t\t\tdel temp_train_set_panda[key]\n",
    "\t\t\t\tdel temp_test_set_panda[key]\n",
    "\t\t\n",
    "\t\tall_temp_train_set = list(temp_train_set_panda.values())\n",
    "\t\tall_temp_test_set = list(temp_train_set_panda.values())\n",
    "  \n",
    "\t\tif len(all_temp_train_set) == 0 or len(all_temp_test_set) == 0:\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Step:\", progress, \"/\", progress_end, \"failed\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tall_train_set = pd.concat(all_temp_train_set)\n",
    "\t\tall_train_set = Dataset.from_pandas(all_train_set, split=\"test\")\n",
    "\t\tall_train_set = sample_dataset(all_train_set, label_column=\"label\", num_samples=n_shot, seed=47*i)\n",
    "\t\tall_test_set = pd.concat(all_temp_test_set)\n",
    "\t\tall_test_set = Dataset.from_pandas(all_test_set, split=\"test\")\n",
    "  \n",
    "\t\ttry:\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "   \n",
    "\t\t\tf1_score, run_time = setfit_f1_score(all_train_set, all_test_set, model, loss)\n",
    "\t\t\tresults['all'].append(f1_score)\n",
    "\t\t\trun_times['all'].append(run_time)\n",
    "\t\texcept Exception as err:\n",
    "\t\t\tprint('all', \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence transformers\n",
    "\n",
    "Test SetFit with different ST models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tmodels = params[\"model\"]\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    " \n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    "\n",
    "\tfor key in models.keys():\n",
    "\t\tresults[key] = []\n",
    "\t\trun_times[key] = []\n",
    "\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * len(models)\n",
    " \n",
    "\tfor i in range(n_iter):\n",
    "\t\t# Use the same subset of the dataset for all of the tests in the following loop\n",
    "\t\tif not (input_length_range is None):\n",
    "\t\t\tnew_train_set = filter_dataset(train_set, input_length_range[0], input_length_range[1])\n",
    "\t\telse:\n",
    "\t\t\tnew_train_set = train_set\n",
    "\t\tnew_train_set = Dataset.from_pandas(new_train_set, split=\"train\")\n",
    "\t\tnew_train_set = sample_dataset(new_train_set, label_column=\"label\", num_samples=n_shot, seed=47*i)\n",
    "\n",
    "\t\tfor key, full_model_name in models.items():\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "   \n",
    "\t\t\ttry:\n",
    "\t\t\t\tf1_score, run_time = setfit_f1_score(new_train_set, new_test_set, full_model_name, loss, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\t\tresults[key].append(f1_score)\n",
    "\t\t\t\trun_times[key].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(key, \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_epochs_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    "\tnum_epochs = params[\"num_epochs\"]\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    " \n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    "\n",
    "\tfor epoch_tuple in num_epochs:\n",
    "\t\tkey = f\"({epoch_tuple[0]}, {epoch_tuple[1]})\"\n",
    "\t\tresults[key] = []\n",
    "\t\trun_times[key] = []\n",
    "\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * len(num_epochs)\n",
    " \n",
    "\tfor i in range(n_iter):\n",
    "\t\t# Use the same subset of the dataset for all of the tests in the following loop\n",
    "\t\tif not (input_length_range is None):\n",
    "\t\t\tnew_train_set = filter_dataset(train_set, input_length_range[0], input_length_range[1])\n",
    "\t\telse:\n",
    "\t\t\tnew_train_set = train_set\n",
    "\t\tnew_train_set = Dataset.from_pandas(new_train_set, split=\"train\")\n",
    "\t\tnew_train_set = sample_dataset(new_train_set, label_column=\"label\", num_samples=n_shot, seed=47*i)\n",
    "\n",
    "\t\tfor epoch_tuple in num_epochs:\n",
    "\t\t\tkey = f\"({epoch_tuple[0]}, {epoch_tuple[1]})\"\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "   \n",
    "\t\t\ttry:\n",
    "\t\t\t\tf1_score, run_time = setfit_f1_score(new_train_set, new_test_set, model, loss, num_epochs=epoch_tuple, batch_size=batch_size)\n",
    "\t\t\t\tresults[key].append(f1_score)\n",
    "\t\t\t\trun_times[key].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(key, \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_params_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    " \n",
    "\tresults = []\n",
    "\trun_times = []\n",
    "\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    "\tprogress = 0\n",
    "\n",
    "\tfor i in range(n_iter):\n",
    "\t\tprogress += 1\n",
    "\t\tprint(\"Step:\", progress, \"/\", n_iter)\n",
    "\t\tif not (input_length_range is None):\n",
    "\t\t\tnew_train_set = filter_dataset(train_set, input_length_range[0], input_length_range[1])\n",
    "\t\telse:\n",
    "\t\t\tnew_train_set = train_set\n",
    "\t\tnew_train_set = Dataset.from_pandas(new_train_set, split=\"train\")\n",
    "\t\tnew_train_set = sample_dataset(new_train_set, label_column=\"label\", num_samples=n_shot, seed=47*i)\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tf1_score, run_time = setfit_f1_score(new_train_set, new_test_set, model, loss, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\tresults.append(f1_score)\n",
    "\t\t\trun_times.append(run_time)\n",
    "\t\texcept Exception as err:\n",
    "\t\t\t\tprint(i, \"failed\", str(err))\n",
    "\treturn {\"all\":results}, {\"all\":run_times}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\robin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import random\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def get_synonyms(word, lang):\n",
    "    l = 'fra' if lang == 'fr' else 'eng'\n",
    "    synonyms=[synset.lemma_names(l) for synset in wordnet.synsets(word, lang=l)]\n",
    "    return synonyms\n",
    "\n",
    "def replace_with_synonym(word, synonyms):\n",
    "\tif synonyms:\n",
    "\t\tsyn = random.choice(synonyms)\n",
    "\t\tif type(syn) == type([]):\n",
    "\t\t\tsyn = random.choice(syn)\n",
    "\treturn word\n",
    "\n",
    "def gen_text_with_synonym_replacement(text, lang, params=None):\n",
    "\tmodification_ratio = 1\n",
    "\tif not (params is None) and \"modification_rate\" in params :\n",
    "\t\tif params[\"modification_rate\"] < 0 or params[\"modification_rate\"] > 1:\n",
    "\t\t\traise Exception(\"Invalid modification_rate (expected a value between 0 and 1)\")\n",
    "\t\telse:\n",
    "\t\t\tmodification_ratio = params[\"modification_rate\"]\n",
    "\t\t\n",
    "\tsentences = sent_tokenize(text)\n",
    "\taugmented_sentences = []\n",
    "\n",
    "\topposite_modification_ratio = 1 - modification_ratio\t\n",
    " \n",
    "\tfor sentence in sentences:\n",
    "\t\ttokenized = word_tokenize(sentence)\n",
    "\t\taugmented_tokens = []\n",
    "\t\tfor token in tokenized:\n",
    "\t\t\tdo_replace_by_synonym = 1 == np.random.choice([0,1], p=[opposite_modification_ratio,modification_ratio])\n",
    "\t\t\tif do_replace_by_synonym:\n",
    "\t\t\t\tsynonyms = get_synonyms(token, lang)\n",
    "\t\t\t\taugmented_tokens.append(replace_with_synonym(token, synonyms))\n",
    "\t\t\telse:\n",
    "\t\t\t\taugmented_tokens.append(token)\n",
    "\t\taugmented_sentence = ' '.join(augmented_tokens)\n",
    "\t\taugmented_sentences.append(augmented_sentence)\n",
    "\t \n",
    "\taugmented_text = ' '.join(augmented_sentences)\n",
    "\treturn augmented_text\n",
    "\n",
    "def augment_synonym_replacement(data, new_samples, n_new_samples_per_class, classes, strategy_params):\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_new_samples_per_class * len(classes)\n",
    "\tdo_continue = True\n",
    "\t\n",
    "\twhile(do_continue and progress < progress_end):     \n",
    "\t\tfor i in range(len(data)):\n",
    "\t\t\tc = data.iloc[i][\"label\"]\n",
    "\t\t\tif(len(new_samples[c]) >= n_new_samples_per_class):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\tprint(\"Data augmentation... (\", progress, \"/\", progress_end,\")\")\n",
    "\t\t\ttry:\n",
    "\t\t\t\tl = detect(data.iloc[i][\"text\"])\n",
    "\t\t\t\tif l != 'fr' and l != 'en':\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tnew_samples[c].append(gen_text_with_synonym_replacement(data.iloc[i][\"text\"], l, strategy_params))\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(\"failed\", str(err))\n",
    "\t\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tif progress >= progress_end:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tdo_continue = False\n",
    "\t\tfor val in new_samples.values():\n",
    "\t\t\tif len(val) < n_new_samples_per_class:\n",
    "\t\t\t\tdo_continue = True\n",
    "\t\n",
    "\treturn new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def gen_text_from_sentences(sentences, length):\n",
    "\tselected_sentences = []\n",
    "\tfor _ in range(length):\n",
    "\t\tselected_sentences.append(random.choice(sentences))\n",
    "\treturn ' '.join(selected_sentences)\n",
    "     \n",
    "\n",
    "def augment_swapping_inter(data, new_samples, n_new_samples_per_class, classes):\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_new_samples_per_class * len(classes)\n",
    "\tmax_text_size = 10 # max number of sentences\n",
    " \n",
    "\tfor c in classes:\n",
    "\t\tfiltered_rows = data[data['label'] == c]\n",
    "\t\tsentences = []\n",
    "\t\tfor i in range(len(filtered_rows)):\n",
    "\t\t\tsentences = sentences + sent_tokenize(filtered_rows.iloc[i][\"text\"])\n",
    "\n",
    "\t\twhile(len(new_samples[c]) < n_new_samples_per_class):\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tprint(\"Data augmentation... (\", progress, \"/\", progress_end,\")\")\n",
    "   \n",
    "\t\t\tlength = randint(1, max(1,min(len(sentences)//4, max_text_size)))\n",
    "\t\t\tnew_text = gen_text_from_sentences(sentences, length)\n",
    "\t\t\tnew_samples[c].append(new_text)\n",
    "\t\t\t\t\n",
    "\treturn new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def augment_crossover(data, new_samples, n_new_samples_per_class, classes, strategy_params=None):\n",
    "\tn_points_crossover = floor(strategy_params[\"n_points_crossover\"]) if not (strategy_params is None) and \"n_points_crossover\" in strategy_params else 1\n",
    "\tif n_points_crossover<0:\n",
    "\t\tn_points_crossover = 1\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_new_samples_per_class * len(classes)\n",
    "\tn_divs = n_points_crossover+1\n",
    " \n",
    "\tfor c in classes:\n",
    "\t\tfiltered_rows = data[data['label'] == c]\n",
    "\t\t\n",
    "\t\twhile(len(new_samples[c]) < n_new_samples_per_class):\n",
    "\t\t\tfor parent1 in range(len(filtered_rows)):\n",
    "\t\t\t\tprogress += 1\n",
    "\t\t\t\tprint(\"Data augmentation... (\", progress, \"/\", progress_end,\")\")\n",
    "    \n",
    "\t\t\t\tparent2 =  random.choice([j for j in range(len(filtered_rows)) if j != parent1])\n",
    "    \n",
    "\t\t\t\tsentences_parent1 = sent_tokenize(filtered_rows.iloc[parent1][\"text\"])\n",
    "\t\t\t\tsentences_parent2 = sent_tokenize(filtered_rows.iloc[parent2][\"text\"])\n",
    "\t\t\t\n",
    "\t\t\t\tchunk_len_parent1 = len(sentences_parent1) // n_divs + (1 if len(sentences_parent1) % n_divs != 0 else 0)\n",
    "\t\t\t\tchunk_len_parent2 = len(sentences_parent2) // n_divs + (1 if len(sentences_parent2) % n_divs != 0 else 0)\n",
    "\t\t\t\ti1 = 0\n",
    "\t\t\t\ti2 = 0\n",
    "\n",
    "\t\t\t\taugmented_sentences = []\n",
    "\n",
    "\t\t\t\tfor _ in range(n_divs):\n",
    "\t\t\t\t\tif i1>=len(sentences_parent1):\n",
    "\t\t\t\t\t\twhile i1>=len(sentences_parent1) and i2 < len(sentences_parent2):\n",
    "\t\t\t\t\t\t\taugmented_sentences.append(sentences_parent2[i2])\n",
    "\t\t\t\t\t\t\ti2 += 1\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telif i2>=len(sentences_parent2):\n",
    "\t\t\t\t\t\twhile i2>=len(sentences_parent2) and i1 < len(sentences_parent1):\n",
    "\t\t\t\t\t\t\taugmented_sentences.append(sentences_parent1[i1])\n",
    "\t\t\t\t\t\t\ti1 += 1\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\ti_parent = random.choice([1,2])\n",
    "\t\t\t\t\t\tif i_parent == 1:\n",
    "\t\t\t\t\t\t\ti_chunk = 0\n",
    "\t\t\t\t\t\t\twhile i_chunk < chunk_len_parent1 and i1<len(sentences_parent1):\n",
    "\t\t\t\t\t\t\t\taugmented_sentences.append(sentences_parent1[i1 + i_chunk])\n",
    "\t\t\t\t\t\t\t\ti_chunk += 1\n",
    "\t\t\t\t\t\t\ti1 += chunk_len_parent1\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\ti_chunk = 0\n",
    "\t\t\t\t\t\t\twhile i_chunk < chunk_len_parent2 and i2<len(sentences_parent2):\n",
    "\t\t\t\t\t\t\t\taugmented_sentences.append(sentences_parent1[i2 + i_chunk])\n",
    "\t\t\t\t\t\t\t\ti_chunk += 1\n",
    "\t\t\t\t\t\t\ti1 += chunk_len_parent2\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\tnew_text = ' '.join(augmented_sentences)\n",
    "\t\t\t\tnew_samples[c].append(new_text)\n",
    "\n",
    "\t\t\t\tif len(new_samples[c]) >= n_new_samples_per_class:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\treturn new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def augment_back_translation(data, new_samples, n_new_samples_per_class, classes):\n",
    "\tmodel_name_fr_en = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "\tmodel_name_en_fr = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "\n",
    "\ttokenizer_fr_en = MarianTokenizer.from_pretrained(model_name_fr_en)\n",
    "\ttokenizer_en_fr = MarianTokenizer.from_pretrained(model_name_en_fr)\n",
    "\tmodel_fr_en = MarianMTModel.from_pretrained(model_name_fr_en)\n",
    "\tmodel_en_fr = MarianMTModel.from_pretrained(model_name_en_fr)\t\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_new_samples_per_class * len(classes)\n",
    "\tdo_continue = True\n",
    " \n",
    "\twhile(do_continue and progress < progress_end):     \n",
    "\t\tfor i in range(len(data)):\n",
    "\t\t\tc = data.iloc[i][\"label\"]\n",
    "\t\t\tif(len(new_samples[c]) >= n_new_samples_per_class):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\tprint(\"Data augmentation... (\", progress, \"/\", progress_end,\")\")\n",
    "\t\t\ttry:\n",
    "\t\t\t\tl = detect(data.iloc[i][\"text\"])\n",
    "\n",
    "\t\t\t\tif l != 'fr' and l != 'en':\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tif l == 'fr':\n",
    "\t\t\t\t\ttemp = model_fr_en.generate(**tokenizer_fr_en(\">>en<< \"+data.iloc[i][\"text\"], return_tensors=\"pt\", padding=True))[0]\n",
    "\t\t\t\t\ttemp = tokenizer_fr_en.decode(temp, skip_special_tokens=True)\n",
    "\t\t\t\t\ttemp = model_en_fr.generate(**tokenizer_en_fr(\">>fr<< \"+temp, return_tensors=\"pt\", padding=True))[0]\n",
    "\t\t\t\t\tnew_samples[c].append(tokenizer_en_fr.decode(temp, skip_special_tokens=True))\n",
    "\t\t\t\telif l == 'en':\n",
    "\t\t\t\t\ttemp = model_en_fr.generate(**tokenizer_en_fr(\">>fr<< \"+data.iloc[i][\"text\"], return_tensors=\"pt\", padding=True))[0]\n",
    "\t\t\t\t\ttemp = tokenizer_en_fr.decode(temp, skip_special_tokens=True)\n",
    "\t\t\t\t\ttemp = model_fr_en.generate(**tokenizer_fr_en(\">>en<< \"+temp, return_tensors=\"pt\", padding=True))[0]\n",
    "\t\t\t\t\tnew_samples[c].append(tokenizer_fr_en.decode(temp, skip_special_tokens=True))\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(\"failed\", str(err))\n",
    "\t\n",
    "\t\t\tprogress += 1\n",
    "\t\t\tif progress >= progress_end:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tdo_continue = False\n",
    "\t\tfor val in new_samples.values():\n",
    "\t\t\tif len(val) < n_new_samples_per_class:\n",
    "\t\t\t\tdo_continue = True\n",
    "    \n",
    "\tdel tokenizer_fr_en\n",
    "\tdel tokenizer_en_fr\n",
    "\tdel model_fr_en\n",
    "\tdel model_en_fr\n",
    " \n",
    "\treturn new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some methods come from: Li, Bohan, Yutai Hou, and Wanxiang Che. \"Data augmentation approaches in natural language processing: A survey.\" Ai Open 3 (2022): 71-90.\n",
    "\n",
    "def augment_data(data, n_new_samples_per_class, classes, strategy='synonym', strategy_params = None):\n",
    "\tif n_new_samples_per_class <= 0:\n",
    "\t\treturn data\n",
    "\n",
    "\tnew_samples = {}\n",
    "\tfor c in classes:\n",
    "\t\tnew_samples[c] = []\n",
    "\n",
    "\tif strategy == \"swapping_inter\":\n",
    "\t\tnew_samples = augment_swapping_inter(data, new_samples, n_new_samples_per_class, classes)\n",
    "\telif strategy == \"back_translation\":\n",
    "\t\tnew_samples = augment_back_translation(data, new_samples, n_new_samples_per_class, classes)\n",
    "\telif strategy == \"synonym_replacement\":\n",
    "\t\tnew_samples = augment_synonym_replacement(data, new_samples, n_new_samples_per_class, classes, strategy_params)\n",
    "\telif strategy == \"crossover\":\n",
    "\t\tnew_samples = augment_crossover(data, new_samples, n_new_samples_per_class, classes, strategy_params)\n",
    "\telse:\n",
    "\t\traise Exception(\"Unknown strategy\")\n",
    "\n",
    "\tgc.collect()\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "\tnewData = data.copy()\n",
    "\tfor c, samples_list in new_samples.items():\n",
    "\t\tfor sample in samples_list:\n",
    "\t\t\tnewData.loc[len(newData.index)] = {\"text\":sample,\"label\":c}\n",
    "\treturn newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation_tests(params, train_set, test_set):\n",
    "\tn_shot = params[\"n_shot\"]\n",
    "\tn_iter = params[\"n_iter\"]\n",
    "\tmodel = params[\"model\"]\n",
    "\tloss = params[\"loss\"]\n",
    "\tinput_length_range = params[\"input_length_range\"] if \"input_length_range\" in params else None\n",
    "\taugmentation_ratios = params[\"data_augmentation_ratio\"]\n",
    "\tstrategy = params[\"data_augmentation_strategy\"]\n",
    "\tnum_epochs = params[\"num_epochs\"] if \"num_epochs\" in params else None\n",
    "\tbatch_size = params[\"batch_size\"] if \"batch_size\" in params else None\n",
    "\tstrategy_params = params[\"strategy_params\"] if \"strategy_params\" in params else None\n",
    "\n",
    "\tresults = {}\n",
    "\trun_times = {}\n",
    "\tfor ratio in augmentation_ratios:\n",
    "\t\tresults[ratio] = []\n",
    "\t\trun_times[ratio] = []\n",
    "\t\n",
    "\tprogress = 0\n",
    "\tprogress_end = n_iter * len(augmentation_ratios)\n",
    " \n",
    "\t# Repeat the tests multiple times because F1-score variations might be due to the examples chosen and not the input length of those examples\n",
    "\tfor i in range(n_iter):\n",
    "\t\t# Use the same subset of the dataset for all of the tests in the following loop\n",
    "\t\tif not (input_length_range is None):\n",
    "\t\t\tnew_train_set = filter_dataset(train_set, input_length_range[0], input_length_range[1])\n",
    "\t\telse:\n",
    "\t\t\tnew_train_set = train_set\n",
    "\t\tnew_train_set = new_train_set.sample(frac = 1, random_state=i*47).groupby('label').head(n_shot)\n",
    "\t\tnew_test_set = Dataset.from_pandas(test_set, split=\"test\")\n",
    "\n",
    "\t\tfor ratio in augmentation_ratios:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tprogress += 1\n",
    "\t\t\t\tprint(\"Step:\", progress, \"/\", progress_end)\n",
    "\n",
    "\t\t\t\tif ratio*n_shot >= n_shot+1:\n",
    "\t\t\t\t\tnew_train_set_augmented = augment_data(new_train_set, round((ratio-1) * n_shot), [0,1], strategy, strategy_params)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnew_train_set_augmented = new_train_set\n",
    "\t\t\t\tnew_train_set_augmented = Dataset.from_pandas(new_train_set_augmented, split=\"test\")\n",
    "\t\t\t\tprint(\"Training...\",end=\"\")\n",
    "\t\t\t\tf1_score, run_time = setfit_f1_score(new_train_set_augmented, new_test_set, model, loss, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\t\t\t\tprint(\"Done\")\n",
    "\t\t\t\tresults[ratio].append(f1_score)\n",
    "\t\t\t\trun_times[ratio].append(run_time)\n",
    "\t\t\texcept Exception as err:\n",
    "\t\t\t\tprint(ratio, \"failed\", str(err))\n",
    "\treturn results, run_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_to_str(loss):\n",
    "    if loss == CosineSimilarityLoss:\n",
    "        return \"Cosine\"\n",
    "    elif loss == BatchAllTripletLoss:\n",
    "        return \"Triplet\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-shots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default SetFit uses the oversampling strategy and the Cosine Similarity loss. For instance if we have 8 positive and 8 negative examples then we have:\n",
    "\n",
    "|   | Y | Y | Y | Y | Y | Y | Y | Y | N | N | N | N | N | N | N | N |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| Y | + | + | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   | + | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   | + | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   | + | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   | + | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   | + | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   |   | + | + | - | - | - | - | - | - | - | - |\n",
    "| Y |   |   |   |   |   |   |   | + | - | - | - | - | - | - | - | - |\n",
    "| N |   |   |   |   |   |   |   |   | + | + | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   | + | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   | + | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   | + | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   | + | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   | + | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   |   | + | + |\n",
    "| N |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   | + |\n",
    "\n",
    "- P = 2 * (8 + 7 + 6 + 5 + 4 + 3 + 2 + 1) \t= 72\n",
    "- N = 8 * 8 = 64 -> + 8 duplications \t\t= 72\n",
    "- Total = 72 + 72 = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": [2, 4, 6, 10, 20, 40, 60, 100],\n",
    "\t\"n_iter\": 10,\n",
    " \t\"n_max_iter_per_shot\": 10,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"loss\": BatchAllTripletLoss\n",
    "}\n",
    "\n",
    "results, run_times = n_shot_tests(params, train_set, test_set)\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/n_shot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_length_range\": [[0,4],[4,5],[5,6],[6,7],[7,8],[8,9],[9,10]],\n",
    "    #[[6,10],[10,15],[15,20],[20,30], [6,15], [15,30], [6,20], [10,30], [6,30]],\n",
    "    # [[0,5],[5,10], [10,50], [50,100],[100,200],[200,350]],\n",
    "    # [[0,9],[1,9],[2,9],[3,9],[4,9],[5,9],[6,9],[7,9],[8,9],[9,9]],\n",
    "    # [[0,9],[9,100],[9,350],[100,350],[0,350]],\n",
    "\t# [[8,50],[8,100],[8,150],[8,200],[8,250],[8,300],[8,350]],\n",
    "\t# [[7,350],[8,350],[9,350],[10,350]],\n",
    "    # [[0,3],[0,4],[0,5],[0,6],[0,7],[0,8],[0,9],[0,10]],\n",
    "    # [[0,5],[0,10],[0,100],[6,100],[200,350]],\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"loss\": BatchAllTripletLoss\n",
    "}\n",
    "\n",
    "results, run_times = input_length_tests(params, train_set, test_set)\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/input_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 10,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"distance\": {\n",
    "\t\t\"Cosine\":BatchHardTripletLossDistanceFunction.cosine_distance,\n",
    "\t\t\"Euclidian\": BatchHardTripletLossDistanceFunction.eucledian_distance, # it's really \"eucledian\" and not \"euclidian\" in the module sentence_transformers\n",
    "\t},\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "}\n",
    "\n",
    "\n",
    "results, run_times = distance_tests(params, train_set, test_set)\n",
    "\n",
    "list_distances = []\n",
    "for key in params[\"distance\"].keys():\n",
    "    list_distances.append(key)\n",
    "params[\"distance\"] = list_distances\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss (pair-wise or Triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"loss\": {\"Cosine\":CosineSimilarityLoss, \"Triplet\":BatchAllTripletLoss}\n",
    "}\n",
    "\n",
    "results, run_times = loss_tests(params, train_set, test_set)\n",
    "\n",
    "list_losses = []\n",
    "for key in params[\"loss\"].keys():\n",
    "    list_losses.append(key)\n",
    "params[\"loss\"] = list_losses\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"lang\": ['fr','en'],\n",
    "\t\"n_iter\": 10,\n",
    "\t\"model\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\"loss\": BatchAllTripletLoss\n",
    "}\n",
    "\n",
    "results, run_times = language_tests(params, train_set, test_set)\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/language')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 10,\n",
    "\t\"n_iter\": 10,\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "\t\"model\": {\n",
    "\t\t# \"instructor-large\":\"hkunlp/instructor-large\",\n",
    "\t\t# \"GIST-small-Embedding-v0\":\"avsolatorio/GIST-small-Embedding-v0\",\n",
    "\t\t\"gte-tiny\":\"TaylorAI/gte-tiny\",\n",
    "\t\t# \"all-mpnet-base-v2-table\":\"deepset/all-mpnet-base-v2-table\",\n",
    "  \t\t\"paraphrase-mpnet-base-v2\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "\t\t# \"all-mpnet-base-v2\":\"sentence-transformers/all-mpnet-base-v2\",\n",
    "\t}\n",
    "}\n",
    "\n",
    "results, run_times = model_tests(params, train_set, test_set)\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 5,\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "\t\"model\": \"paraphrase-mpnet-base-v2\",\n",
    "\t\"num_epochs\": [(8,1),(8,2),(8,4),(8,8),(8,10),(8,20),(8,30),(8,40)], \n",
    "\t#[(1,1),(2,1),(4,1),(8,1),(16,1),(32,1),(64,1)], \n",
    "\t#[(1,1),(1,2),(1,4),(1,8),(1,12),(1,16),(1,20),(1,25),(1,30)],\n",
    "}\n",
    "\n",
    "results, run_times = num_epochs_tests(params, train_set, test_set)\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/num_epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling\n",
    "\n",
    "Run multiple tests with different training sets but the same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 10,\n",
    "\t\"n_iter\": 20,\n",
    "\t\"loss\": CosineSimilarityLoss,\n",
    "\t\"model\": \"paraphrase-mpnet-base-v2\",\n",
    "\t\"num_epochs\":(8,1),\n",
    "\t\"data_augmentation_ratio\":[1.2],\n",
    "\t\"input_length_range\":[0,9],\n",
    "}\n",
    "\n",
    "results, run_times = constant_params_tests(params, train_set, test_set)\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/data_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For now we only use a back translation technique and synonym replacement, but we could try other ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 10,\n",
    "\t\"n_iter\": 50,\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "\t\"model\": \"paraphrase-mpnet-base-v2\",\n",
    "\t\"num_epochs\":(8,1),\n",
    " \t\"data_augmentation_ratio\":[1,1.1], # no data augmentation and + 10 %\n",
    "\t\"data_augmentation_strategy\":\"swapping_inter\",\n",
    "\t# \"strategy_params\": {\n",
    "\t# \t\"modification_rate\": 0.2,\n",
    "\t# }\n",
    "}\n",
    "\n",
    "results, run_times = data_augmentation_tests(params, train_set, test_set)\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/data_augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset multi labels transforms\n",
    "\n",
    "Only select labels 0,1,3,4 and then 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\t\"n_shot\": 8,\n",
    "\t\"n_iter\": 80,\n",
    "\t\"loss\": BatchAllTripletLoss,\n",
    "\t\"model\": \"paraphrase-mpnet-base-v2\",\n",
    "}\n",
    "\n",
    "tested_training_sets = {\n",
    "\t\"all_labels\": train_set,\n",
    "\t\"likely_labels\":train_set_likely_labels,\n",
    "\t\"sure_labels\":train_set_sure_labels,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "run_times = {}\n",
    "progress = 0\n",
    "progress_end = len(tested_training_sets)\n",
    "for training_set_key, training_set_data in tested_training_sets.items():\n",
    "\tprint(\"Test: \", progress,\"/\",progress_end)\n",
    "\ttemp_results, temp_run_times = constant_params_tests(params, training_set_data, test_set)\n",
    "\tresults[training_set_key] = temp_results[\"all\"]\n",
    "\trun_times[training_set_key] = temp_run_times[\"all\"]\n",
    "\n",
    "\n",
    "params[\"loss\"] = loss_to_str(params[\"loss\"])\n",
    "params[\"training_set\"] = list(tested_training_sets.keys())\n",
    "save_to_json({\"results\":results, \"run_times\":run_times, \"params\": params},  r'../results/setfit/training_set_labels_restriction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to fetch data from result files (in JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_data(filename, folder):\n",
    "\twith open(folder+\"/\"+filename, 'r') as file:\n",
    "\t\tdata = json.load(file)\n",
    " \n",
    "\treturn data['results'], data['run_times'], data['params']\n",
    "\n",
    "def load_latest_results_data(folder):\n",
    "\tfilenames = os.listdir(folder)\n",
    "\tlatest = max(filenames, key=lambda x: os.path.getmtime(os.path.join(folder, x)))\n",
    "\treturn load_results_data(latest, folder)\n",
    "\n",
    "def load_all_results_data(folder, test_name, filters={}):\n",
    "\tfilenames_list = os.listdir(folder)\n",
    "\tall_data = {\"results\":{}, \"run_times\":{}}\n",
    " \n",
    " \n",
    "\tfor filename in filenames_list:\n",
    "\t\tdo_add_data = True\n",
    "\t\ttested_param = test_name\n",
    "\t\tnew_data = {\"results\":{}, \"run_times\":{}}\n",
    "  \n",
    "\t\twith open(folder+\"/\"+filename, 'r') as file:\n",
    "\t\t\tdata = json.load(file)\n",
    "\t\t\tfor param_key, param_value in data[\"params\"].items():\n",
    "\t\t\t\tif not (param_key in filters):\n",
    "\t\t\t\t\t# No filter\n",
    "\t\t\t\t\tif param_key == tested_param:\n",
    "\t\t\t\t\t\tnew_data[\"results\"] = data[\"results\"]\n",
    "\t\t\t\t\t\tnew_data[\"run_times\"] = data[\"run_times\"]\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\tif type(filters[param_key]) != type([]) and type(filters[param_key]) != type({}):\n",
    "\t\t\t\t\tfilters[param_key] = [filters[param_key]]\n",
    "\n",
    "\t\t\t\tif type(param_value) == type([]) and len(param_value)>0 and type(param_value[0]) == type([]):\n",
    "\t\t\t\t\tfor i in range(len(param_value)):\n",
    "\t\t\t\t\t\tparam_value[i] = f\"[{param_value[i][0]},{param_value[i][1]}]\"\n",
    "\n",
    "\t\t\t\tif type(param_value) == type({}) and type(filters[param_key]) == type({}):\n",
    "\t\t\t\t\tfor sub_filter_key, sub_filter_val in filters[param_key].items():\n",
    "\t\t\t\t\t\tif not (sub_filter_key in param_value) or param_value[sub_filter_key] != sub_filter_val:\n",
    "\t\t\t\t\t\t\tdo_add_data = False\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tif type(filters[param_key][0]) == type([]):\n",
    "\t\t\t\t\tfor i in range(len(filters[param_key])):\n",
    "\t\t\t\t\t\tfilters[param_key][i] = f\"[{filters[param_key][i][0]},{filters[param_key][i][1]}]\"\n",
    "      \n",
    "\t\t\t\tif param_key == tested_param:\n",
    "\t\t\t\t\tfor filter_value in filters[param_key]:\n",
    "\t\t\t\t\t\tif filter_value in param_value:\n",
    "\t\t\t\t\t\t\tnew_data[\"results\"][filter_value] = data[\"results\"][str(filter_value)]\n",
    "\t\t\t\t\t\t\tnew_data[\"run_times\"][filter_value] = data[\"run_times\"][str(filter_value)]\n",
    "\t\t\t\telif not (param_value in filters[param_key]):\n",
    "\t\t\t\t\tdo_add_data = False\n",
    "\t\t\t\t\tbreak\n",
    " \n",
    "\t\tif do_add_data == True:\n",
    "\t\t\tfor output_type in new_data.keys(): # results and run_times\n",
    "\t\t\t\tfor key in new_data[output_type].keys():\n",
    "\t\t\t\t\tif key in all_data[output_type]:\n",
    "\t\t\t\t\t\tall_data[output_type][key] = np.concatenate((all_data[output_type][key], new_data[output_type][key]))\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tall_data[output_type][key] = new_data[output_type][key]\n",
    "\tisSorted = False\n",
    "\ttry:\n",
    "\t\t# Try to sort the keys if they are number\n",
    "\t\tall_data[\"results\"] = dict(sorted(all_data[\"results\"].items(), key=lambda x: float(x[0])))\n",
    "\t\tall_data[\"run_times\"] = dict(sorted(all_data[\"run_times\"].items(), key=lambda x: float(x[0])))\n",
    "\t\tisSorted = True\n",
    "\texcept:\"\"\n",
    "\tif not isSorted:\n",
    "\t\ttry:\n",
    "\t\t\t# Try to sort the keys if they are pairs of numbers (tuples or lists)\n",
    "\t\t\tall_data[\"results\"] = dict(sorted(all_data[\"results\"].items(), key=lambda x: (float(json.loads(x[0])[0]),float(json.loads(x[0])[1]))))\n",
    "\t\t\tall_data[\"run_times\"] = dict(sorted(all_data[\"run_times\"].items(), key=lambda x: (float(json.loads(x[0])[0]),float(json.loads(x[0])[1]))))\n",
    "\t\texcept:\"\"\n",
    "\treturn all_data['results'], all_data['run_times']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to create the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_scatter_line_plot(data, title, xlabel, ylabel):\n",
    "\tresultsMeans = {}\n",
    "\n",
    "\tfor key in data.keys():\n",
    "\t\tif len(data[key]) > 0:\n",
    "\t\t\tresultsMeans[key] = np.mean(data[key])\n",
    "\t\telse:\n",
    "\t\t\tresultsMeans[key] = 0.0\n",
    "\n",
    "\txMean = list(resultsMeans.keys())\n",
    "\tyMean = list(resultsMeans.values())\n",
    "\n",
    "\tlistOfLists = list(data.values())\n",
    "\n",
    "\txAll = []\n",
    "\tfor i in range(len(listOfLists)): # for each key\n",
    "\t\tfor _ in range(len(listOfLists[i])): # for each repetition of the key\n",
    "\t\t\txAll.append(xMean[i])\n",
    "\tyAll = np.concatenate(list(data.values()))\n",
    "\t\n",
    "\tplt.figure(figsize=(8, 6))\n",
    "\tplt.plot(xMean, yMean, marker='', linestyle='-')\n",
    "\tplt.scatter(xAll, yAll)\n",
    "\t\n",
    "\tfor i in range(len(xMean)):\n",
    "\t\tplt.text(xMean[i], yMean[i], f'{yMean[i]:.2f}', ha='center', bbox = dict(facecolor = 'white', alpha =.8))\n",
    "\t\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel(xlabel)\n",
    "\tplt.ylabel(ylabel)\n",
    "\t\n",
    "\tplt.grid(True)\n",
    "\tplt.show()\n",
    "\n",
    "def create_bar_plot(data, title, xlabel, ylabel, vertical_xticks=False):\n",
    "\tresultsMeans = {}\n",
    "\n",
    "\tfor key in data.keys():\n",
    "\t\tif len(data[key]) > 0:\n",
    "\t\t\tresultsMeans[key] = np.mean(data[key])\n",
    "\n",
    "\txMean = list(resultsMeans.keys())\n",
    "\tyMean = list(resultsMeans.values())\n",
    "\t\n",
    "\tplt.figure(figsize=(11, 6))\n",
    "\tif vertical_xticks:\n",
    "\t\tplt.xticks(fontsize=15, rotation='vertical')\n",
    "\telse:\n",
    "\t\tplt.xticks(fontsize=15)\n",
    "\tplt.yticks(fontsize=15)\n",
    "\n",
    "\tfor i in range(len(xMean)):\n",
    "\t\tplt.text(i, yMean[i], f'{yMean[i]:.2f}', ha = 'center', bbox = dict(facecolor = 'white', alpha =.8))\n",
    " \n",
    "\tplt.bar(xMean, yMean)\n",
    "\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel(xlabel)\n",
    "\tplt.ylabel(ylabel)\n",
    "\n",
    "\tplt.show()\n",
    " \n",
    " \n",
    "def create_boxplot(data, title, xlabel, ylabel, vertical_xticks=False):\n",
    "\tmedians = {}\n",
    "\tfor key, value in data.items():\n",
    "\t\tmedians[key] = np.median(value)\n",
    "\n",
    "\tplt.figure(figsize=(8, 6))\n",
    "\tplt.boxplot(data.values())\n",
    "\t\n",
    "\tif vertical_xticks:\n",
    "\t\tplt.xticks(ticks=list(range(1,len(data)+1)) ,labels=data.keys(), rotation='vertical')\n",
    "\telse:\n",
    "\t\tplt.xticks(ticks=list(range(1,len(data)+1)) ,labels=data.keys())\n",
    "\t\n",
    "\ti = 1 \n",
    "\tfor key in data.keys():\n",
    "\t\tplt.text(i, medians[key], f'{medians[key]:.2f}', ha='center', bbox = dict(facecolor = 'white', alpha =.8))\n",
    "\t\ti += 1\n",
    "\t\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel(xlabel)\n",
    "\tplt.ylabel(ylabel)\n",
    "\t\n",
    "\tplt.grid(True)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot latest graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/n_shot')\n",
    "# create_boxplot(results, 'Effect of the number of shots on F1-score', 'N-shot', 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the N-shot tests', 'N-shot', 'Run time (s)')\n",
    "\n",
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/input_length')\n",
    "# create_boxplot(results, 'Effect of the length of the input on F1-score (train set only)', 'Number of words', 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the input length tests', 'Number of words', 'Run time (s)')\n",
    "\n",
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/distance')\n",
    "# create_boxplot(results, 'Effect of the distance on F1-score', 'Distance', 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the distance tests', 'Distance', 'Run time (s)')\n",
    "\n",
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/loss')\n",
    "# create_boxplot(results, 'Effect of the loss on F1-score', 'Loss', 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the distance tests', 'Loss', 'Run time (s)')\n",
    "\n",
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/language')\n",
    "# create_boxplot(results, 'Effect of the language on F1-score (train and test sets)', 'Language', 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the language tests', 'Language', 'Run time (s)')\n",
    "\n",
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/model')\n",
    "# create_boxplot(results, 'Effect of the Sentence Transformer model on F1-score', 'Model', 'F1-score', vertical_xticks=True)\n",
    "# create_bar_plot(run_times, 'Runtime for the Sentence Transformer model tests', 'Model', 'Run time (s)', vertical_xticks=True)\n",
    "\n",
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/num_epoch')\n",
    "# create_boxplot(results, 'Effect of the number of epochs on F1-score', 'Number of epochs', 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the number of epochs tests', 'Number of epochs', 'Run time (s)')\n",
    "\n",
    "# results, run_times, _ = load_latest_results_data(r'../results/setfit/head_learning_rate')\n",
    "# create_boxplot(results, 'Effect of the head learning rate on F1-score', 'Head learning rate', 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the head learning rate tests', 'Head learning rate', 'Run time (s)')\n",
    "\n",
    "# results, run_times, params = load_latest_results_data(r'../results/setfit/data_sampling')\n",
    "# create_boxplot(results, f\"F1-score with the same params with {params['n_iter']} different support sets\", str(params), 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for the same params', str(params), 'Run time (s)')\n",
    "\n",
    "# results, run_times, params = load_latest_results_data(r'../results/setfit/data_augmentation')\n",
    "# create_boxplot(results, \"Effect of data augmentation on F1-score\", \"Data augmentation ratio\", 'F1-score')\n",
    "# create_bar_plot(run_times, 'Runtime for data augmentation tests', \"Data augmentation ratio\", 'Run time (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot graphs using all data and filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# results, run_times = load_all_results_data(r'../results/setfit/n_shot', \"n_shot\")\n",
    "# create_boxplot(results, 'Effect of the number of shots on F1-score', 'N-shot', 'F1-score')\n",
    "\n",
    "# results, run_times = load_all_results_data(r'../results/setfit/input_length', \"input_length_range\", {\"input_length_range\":[[0,2],[1,3],[0,3],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9],[9,10]]})\n",
    "# create_boxplot(results, 'Effect of the length of the input on F1-score (train set only)', 'Number of words', 'F1-score')\n",
    "\n",
    "# results, run_times = load_all_results_data(r'../results/setfit/language', \"lang\", {\"model\":\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \"n_shot\":8})\n",
    "# create_boxplot(results, 'Effect of the language on F1-score (train and test sets) (multilingual model) (8 shots)', 'Language', 'F1-score')\n",
    "\n",
    "# results, run_times = load_all_results_data(r'../results/setfit/language', \"lang\", {\"model\":\"sentence-transformers/paraphrase-mpnet-base-v2\", \"n_shot\":8})\n",
    "# create_boxplot(results, 'Effect of the language on F1-score (train and test sets) (not multilingual model) (8 shots)', 'Language', 'F1-score')\n",
    "\n",
    "# results, run_times = load_all_results_data(r'../results/setfit/model', \"model\", {\"n_shot\":8})\n",
    "# create_boxplot(results, 'Effect of the model on F1-score (8 shots)', 'Model', 'F1-score', vertical_xticks=True)\n",
    "\n",
    "# for strategy in [\"back_translation\", \"synonym_replacement\", \"crossover\", \"swapping_inter\"]:\n",
    "# \tresults, run_times = load_all_results_data(r'../results/setfit/data_augmentation', \"data_augmentation_ratio\", {\"data_augmentation_strategy\":strategy})\n",
    "# \tcreate_boxplot(results, f\"Effect of the data augmentation ratio on F1-score (8 shots) (strategy: {strategy})\", 'Data augmentation ratio', 'F1-score')\n",
    "\n",
    "# for i in [0.1,0.3,0.5,0.8,1]:\n",
    "# \tresults, run_times = load_all_results_data(r'../results/setfit/data_augmentation', \"data_augmentation_ratio\", {\"data_augmentation_strategy\":\"synonym_replacement\", \"strategy_params\":{\"modification_rate\":i}})\n",
    "# \tcreate_boxplot(results, f\"Effect of the data augmentation ratio (with synonyms) on F1-score (8 shots) (modification_ratio: {i})\", 'Data augmentation ratio', 'F1-score')\n",
    "\n",
    "results, run_times = load_all_results_data(r'../results/setfit/training_set_labels_restriction', \"model\")\n",
    "create_boxplot(results, 'Effect of the training set labels restriction on F1-score (8 shots)', 'Model', 'F1-score', vertical_xticks=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
